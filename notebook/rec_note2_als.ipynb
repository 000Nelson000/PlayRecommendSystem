{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推薦模型 - 矩陣分解\n",
    "\n",
    "在之前的介紹裡面，相似度關係是利用交易資料所形成的向量空間，而對兩兩用戶(或物品)來求得的。但是實務上使用這個方法會碰到問題：\n",
    "\n",
    "1. 維度過於龐大與稀疏，例如電子商務網站會有上百萬個用品。而單一用戶往往只有很少量(數個）與物品的交互關係(交易紀錄interaction data)此時會形成[維度災難](https://zh.wikipedia.org/wiki/%E7%BB%B4%E6%95%B0%E7%81%BE%E9%9A%BE)，亦即在維度過大的情況下，所有的東西(人)相似度趨近於0(距離無窮遠)\n",
    "2. 計算用戶（或物品)的兩兩關係會隨著用戶(物品）增加而耗時成指數增加\n",
    "\n",
    "矩陣分解目的是解決**維度災難**的手法\n",
    "## 矩陣分解\n",
    "\n",
    "在矩陣分解的想法裡面，把用戶與物品的交易矩陣，用一種線性關係來逼近，\n",
    "\n",
    "$$r_{ui} = \\textbf{x}_u^T \\cdot \\textbf{y}_i $$\n",
    "\n",
    "代表的意思為，用戶購買某商品的背後，有一種隱性特徵來決定購買的權重。而每個商品有關於這個隱性特徵的比例。這樣的線性關係，恰恰決定了用戶對某商品的打分。\n",
    "\n",
    "- 舉例來說: 小明會給**超人特攻隊** `評分=5`, 原因可能是這部片背後有三種特徵: $\\textbf{y}_{超人特攻隊}=$ `{ 恐怖：0, 喜劇：2, 卡通:3 }`,而小明對這三種特徵的喜好程度分別是: $\\textbf{x}_{小明}$ = `{喜愛恐怖:0, 喜愛喜劇:0.9, 喜愛卡通: 1}`。按照矩陣分解的想法：\n",
    "\n",
    "$$r_{小明-超人特攻隊} = \\textbf{x}_{小明}^T \\cdot \\textbf{y}_{超人特攻隊} = 1.8 + 3 = 4.8 \\approx 5$$\n",
    "\n",
    "- 損失函數可寫成 \n",
    "$$\n",
    "L = \\sum_{u,i \\in S} \\left(r_{ui} - \\textbf{x}_u \\cdot \\textbf{y}_i\\right)^2 + \\lambda_x \\sum_u \\left\\Vert \\textbf{x}_u \\right\\Vert ^2  + \\lambda_y \\sum_i \\left\\Vert \\textbf{y}_i \\right\\Vert ^2 $$\n",
    "\n",
    "> 集合$s$表示有評分的物件(交互作用),$x_u,y_i$分別表示用戶$u$(物品$i$)的向量表示,$\\lambda_x,\\lambda_y$表示regularization\n",
    "\n",
    "## explicit ALS 算法\n",
    "\n",
    "- 要最小化此損失函數，可以先固定 $\\textbf{y}_i$為常數對另一變數$\\textbf{x}_u$進行微分，並另其為0求得關係...\n",
    "- 相似的固定 $\\textbf{x}_u$為常數，對另一變數$\\textbf{y}_i$進行微分。\n",
    "- 重複上述動作直到收斂\n",
    "\n",
    "上述過程稱為Alternative Least Square (ALS)算法，由於物標函數是評價分數(1-5)的明顯用戶回饋分數，所以稱為explicit ALS算法。概念上的框架是基於矩陣分解，而針對兩組方程用交互迭代的方式取得收斂。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit ALS 算法\n",
    "\n",
    "其實很常見的狀況是無從知道到底用戶對商品的評價是什麼，只能隱約猜測有買過的東西，對其偏好(preference)程度較高。但是對於沒有買過的商品，沒有購買存有兩種可能性\n",
    "1. 不喜歡此類商品\n",
    "2. 未察覺此商品\n",
    "\n",
    "在此篇[論文](http://yifanhu.net/PUB/cf.pdf)中提出信心程度的想法，將explicit ALS做進一步的改良。\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "L = \\sum_{u,i \\in all} c_{ui}\\left(p_{ui} - \\textbf{x}_u \\cdot \\textbf{y}_i\\right)^2 + \\lambda_x \\sum_u \\left\\Vert \\textbf{x}_u \\right\\Vert ^2  + \\lambda_y \\sum_i \\left\\Vert \\textbf{y}_i \\right\\Vert ^2 \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "其中$p_{ui}$為喜歡或不喜歡${0,1}$之偏好，而$c_{ui}$代表說明用戶$u$對商品$i$之說明喜歡(或不喜歡)的信心程度，數值愈高代表信心程度愈大。與之前僅考慮有交互作用($\\in S$)的情況不同，需要考慮所有未購買的狀況($\\in all_{ui}$)。類似explicit解法，可以透過固定其中一個變數$\\textbf{Y}_i$，微分後為零求得解析解(此解代表能使目標函數最小化)\n",
    "\n",
    "\n",
    "$$\n",
    "\\textbf{X}_u = \\left( \\textbf{Y}^T\\textbf{C}^u\\textbf{Y}  + \\lambda \\textbf{I}\\right)^{-1} \\textbf{Y}^T\\textbf{C}^uP(u)\n",
    "$$\n",
    "\n",
    ">若用戶有$m$個,商品有$n$個\n",
    "\n",
    "> $\\textbf{X}_u$代表用戶u的特徵向量($\\in f\\times 1$)\n",
    "\n",
    "> $\\textbf{Y}$為物品特徵向量縱向堆疊(`vstack`)的矩陣($\\in n\\times f$)\n",
    "\n",
    "> $\\textbf{C}^u$為對角線上才有值的$n \\times n$矩陣\n",
    "\n",
    "> $P(u)\\in\\mathbf{R}^{n\\times 1}$包含每個用戶的喜好(1 or 0)二元結果\n",
    "\n",
    "同理可以取得\n",
    "$$\n",
    "\\textbf{Y}_i = \\left( \\textbf{X}^T\\textbf{C}^i\\textbf{X}  + \\lambda \\textbf{I}\\right)^{-1} \\textbf{X}^T\\textbf{C}^iP(i)\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### 計算效能:\n",
    "\n",
    "在上式中每個用戶的特徵向量$\\textbf{X}_u$取得，必須依賴於\n",
    "\n",
    "1. $\\textbf{Y}^T\\textbf{C}^u\\textbf{Y},$需耗時$\\mathcal{O}(f^2n)$\n",
    "2. $\\textbf{Y}^T\\textbf{C}^u P(u)$ 其中$P(u)$大部分為零，除了少數有與商品作用的$\\textit{u}_n$個人($\\textit{u}_n \\ll n$)\n",
    "3. 反矩陣$\\left( \\textbf{X}^T\\textbf{C}^i\\textbf{X}  + \\lambda \\textbf{I}\\right)^{-1}$\n",
    "\n",
    "$\\textbf{Y}^T\\textbf{C}^u\\textbf{Y}$進一步寫成$\\textbf{Y}^T\\left( \\textbf{C}^u - 1\\right)\\textbf{Y} + \\textbf{Y}^T\\textbf{Y}$後一項不依賴於$u$僅需計算一次(不需要在用戶迴圈之中)，而前一項中的$\\textbf{C}^u - 1$只有$\\textit{u}_n$個非零項，可以大幅簡化計算為$\\mathcal{O}(f^2\\textit{n}_u)$。\n",
    "\n",
    "\n",
    "* 詳細推倒看[這裡](http://datamusing.info/blog/2015/01/07/implicit-feedback-and-collaborative-filtering/)使用Dirac notation,或[這裡](https://math.stackexchange.com/questions/1072451/analytic-solution-for-matrix-factorization-using-alternating-least-squares/1073170#1073170)\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 實作3D模型資料\n",
    "## 前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rec_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelname    632832\n",
      "mid          632832\n",
      "uid          632832\n",
      "dtype: int64\n",
      "modelname    632677\n",
      "mid          632677\n",
      "uid          632677\n",
      "dtype: int64\n",
      "Starting interactions info\n",
      "Number of rows: 62583\n",
      "Number of cols: 28806\n",
      "Sparsity: 0.04%\n",
      "Ending interactions info\n",
      "Number of rows: 13496\n",
      "Number of columns: 13618\n",
      "Sparsity: 0.25%\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../rec-a-sketch/model_likes_anon.psv',\n",
    "                 sep='|',quotechar='\\\\',quoting=csv.QUOTE_MINIMAL)\n",
    "print(df.count())\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(df.count())\n",
    "df = threshold_interaction(df,rowname='uid',colname='mid',row_min=5,col_min=10)\n",
    "inter,uid_to_idx,idx_to_uid,mid_to_idx,idx_to_mid=df_to_spmatrix(df,'uid','mid')\n",
    "train,test, user_idxs = train_test_split(inter,split_count=1,fraction=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implicit ALS算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def alternating_least_squares(Cui, factors, regularization, iterations=20):\n",
    "    users, items = Cui.shape\n",
    "\n",
    "    X = np.random.rand(users, factors) * 0.01\n",
    "    Y = np.random.rand(items, factors) * 0.01\n",
    "\n",
    "    Ciu = Cui.T.tocsr()\n",
    "    for iteration in range(iterations):\n",
    "        X,Y = least_squares(Cui, X, Y, regularization)\n",
    "        Y,X = least_squares(Ciu, Y, X, regularization)\n",
    "        print('iter:{}'.format(iteration))\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares(Cui, X, Y, regularization):\n",
    "    users, factors = X.shape\n",
    "    YtY = Y.T.dot(Y)\n",
    "\n",
    "    for u in range(users):\n",
    "        # accumulate YtCuY + regularization * I in A\n",
    "        A = YtY + regularization * np.eye(factors)\n",
    "\n",
    "        # accumulate YtCuPu in b\n",
    "        b = np.zeros(factors)\n",
    "#         if u % 1000 == 0:\n",
    "#             print(u)\n",
    "        for i in Cui[u,:].indices:\n",
    "            confidence = Cui[u,i]\n",
    "            factor = Y[i]\n",
    "            A += (confidence - 1) * np.outer(factor, factor)\n",
    "            b += confidence * factor\n",
    "\n",
    "        # Xu = (YtCuY + regularization * I)^-1 (YtCuPu)\n",
    "        X[u] = np.linalg.solve(A, b)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a59ee7efdaf8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0musers_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malternating_least_squares\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mregularization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# time consuming : 15~20 min\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-149b393bcbd8>\u001b[0m in \u001b[0;36malternating_least_squares\u001b[1;34m(Cui, factors, regularization, iterations)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mCiu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCui\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleast_squares\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularization\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleast_squares\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCiu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularization\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iter:{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-76e74bc23976>\u001b[0m in \u001b[0;36mleast_squares\u001b[1;34m(Cui, X, Y, regularization)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mconfidence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCui\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mfactor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mA\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mconfidence\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mconfidence\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mouter\u001b[1;34m(a, b, out)\u001b[0m\n\u001b[0;32m   1152\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "users_embedding, items_embedding = alternating_least_squares(train,50,regularization=1,iterations=10) # time consuming : 15~20 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "items_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TopRelated:\n",
    "    ## 利用向量內積，查找最鄰近的物品(cosine based)\n",
    "    def __init__(self, items_factors):\n",
    "        ## 初始化需要正規化物品向量\n",
    "        norms = np.linalg.norm(items_factors, axis=1)\n",
    "        self.factors = items_factors / norms[:, np.newaxis]\n",
    "\n",
    "    def get_related(self, itemid, N=10):\n",
    "        scores = self.factors.dot(self.factors[itemid]) # cosine \n",
    "        best = np.argpartition(scores, -N)[-N:] # partion --> 小於此的放在左側\n",
    "        return sorted(zip(best, scores[best]), key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_related = TopRelated(items_embedding)\n",
    "top_related.get_related(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ApproximateTopRelated:\n",
    "    def __init__(self, items_factors, treecount=20):\n",
    "        index = annoy.AnnoyIndex(items_factors.shape[1], 'angular')\n",
    "        for i, row in enumerate(items_factors):\n",
    "            index.add_item(i, row)\n",
    "        index.build(treecount)\n",
    "        self.index = index\n",
    "\n",
    "    def get_related(self, itemid, N=10):\n",
    "        neighbours = self.index.get_nns_by_item(itemid, N)\n",
    "        return sorted(((other, 1 - self.index.get_distance(itemid, other))\n",
    "                      for other in neighbours), key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "approx_topRelated_item = ApproximateTopRelated(items_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "approx_topRelated_item.get_related(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 評估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## item based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[0,].indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topNrecommend_ibcf(uid, items_factor, inter,nn=10,topN=10):\n",
    "    top_related = TopRelated(items_factor)\n",
    "    topN_dict = defaultdict(int)\n",
    "    for item in inter[uid,].indices:\n",
    "        topn_items = top_related.get_related(item,N=nn) ## cosine 相似\n",
    "        for k,v in topn_items:\n",
    "            topN_dict[k] += v\n",
    "            \n",
    "    sort_ids = sorted(topN_dict, key=topN_dict.get, reverse=True)[:topN] # sorted itemid by scores\n",
    "    scores = [topN_dict[e] for e in sort_ids]\n",
    "    return zip(sort_ids,scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用戶0推薦..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topn_items= topNrecommend_ibcf(uid=0,items_factor=items_embedding,inter=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(topn_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(train, test,user_idxs,items_factors=None,users_factors=None,nn=50, kind='ibcf'):\n",
    "    hits = 0\n",
    "    for user in tqdm(user_idxs):\n",
    "        ## recommend topn items\n",
    "        if kind == 'ibcf':\n",
    "            topn_items = topNrecommend_ibcf(user, items_factors, inter=train,nn=nn)\n",
    "        elif kind =='ubcf':\n",
    "            topn_items = topNrecommend_ubcf(user, users_factors, inter=train, nn=nn)\n",
    "        elif kind == 'inner':\n",
    "            innerProduct = items_factors.dot(users_factors[user])\n",
    "            topn_k = np.argsort(-innerProduct)[:10]\n",
    "            topn_v = [innerProduct[e] for e in topn_k]\n",
    "            topn_items = zip(topn_k,topn_v)\n",
    "        ## real(test) item -- only 1 data exist in each test user\n",
    "        y_item = test[user].indices\n",
    "        score = 1 if y_item in list(zip(*topn_items))[0] else 0\n",
    "        hits += score\n",
    "    return hits/len(user_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate(train, test, user_idxs, items_factors=items_embedding,kind='ibcf') ## 5.4 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topNrecommend_ubcf(uid, users_factor, inter,nn=10,topN=10):\n",
    "    top_related = TopRelated(users_factor)\n",
    "    topN_dict = defaultdict(float)           \n",
    "    topn_users = top_related.get_related(uid,N=nn) ## cosine 相似\n",
    "    for top_u,v in topn_users:\n",
    "        ## top_u買什麼\n",
    "        for item in inter[top_u,].indices:\n",
    "            topN_dict[item] += v\n",
    "\n",
    "    sort_ids = sorted(topN_dict, key=topN_dict.get, reverse=True)[:topN] # sorted itemid by scores\n",
    "    scores = [topN_dict[e] for e in sort_ids]\n",
    "    return zip(sort_ids,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(topNrecommend_ubcf(0,users_embedding, train, nn=50, topN=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate(train,test,user_idxs,users_factors=users_embedding, kind='ubcf', nn=50) # 8.1 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner Product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate(train,test,user_idxs,users_factors=users_embedding,items_factors=items_embedding, kind='inner', nn=50) # 8.1 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit\n",
    "利用[implicit](https://github.com/benfred/implicit)套件來做"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train64 = train.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import implicit\n",
    "# initialize a model\n",
    "model = implicit.als.AlternatingLeastSquares(factors=50,regularization=0.01)\n",
    "\n",
    "# train the model on a sparse matrix of item/user/confidence weights\n",
    "model.fit(train64.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# recommend items for a user\n",
    "user_items = train64.tocsr()\n",
    "recommendations = model.recommend(0, user_items)\n",
    "\n",
    "# find related items\n",
    "related = model.similar_items(itemid=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## evaluate \n",
    "evaluate(train,test,user_idxs,items_factors=model.item_factors, users_factors=model.user_factors,nn=50,kind='inner') # 6.26%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp = model.explain(userid=0,user_items=user_items,itemid=18)\n",
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(train,test,model,user_idxs):\n",
    "    hits = 0\n",
    "    for user in tqdm(user_idxs):\n",
    "        topn_items = model.recommend(user,train)\n",
    "        y_item = test[user].indices\n",
    "        score = 1 if y_item in list(zip(*topn_items))[0] else 0\n",
    "        hits += score\n",
    "    return hits/len(user_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 移除已推薦過的\n",
    "evaluate_model(train,test,model,user_idxs) # 7.3%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 調參數\n",
    "grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import itertools\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_recall(model,train,test,user_idxs):\n",
    "    \"\"\"\n",
    "    train: (csr_matrix) -- should be float64 \n",
    "        u-i sparse matrix for training \n",
    "    model: (implicit)\n",
    "        implicit model \n",
    "    user_idxs: (list)\n",
    "        user idxs for test \n",
    "    \"\"\"\n",
    "    hits = 0\n",
    "    for user in user_idxs:\n",
    "        topn_items = model.recommend(user,train)\n",
    "        y_item = test[user].indices ##  1 data each user (in my case)\n",
    "        score = 1 if y_item in list(zip(*topn_items))[0] else 0\n",
    "        hits += score\n",
    "    return hits/len(user_idxs)\n",
    "\n",
    "def grid_search_learning_curve(model,train,test,param_grids,user_idxs):\n",
    "    curves = []\n",
    "    keys,values = zip(*param_grids.items())\n",
    "    for value in itertools.product(*values):\n",
    "        params = dict(zip(keys,value))\n",
    "        this_model = copy.deepcopy(model)\n",
    "        for k,v in params.items():\n",
    "            setattr(this_model,k,v)\n",
    "        this_model.fit(train64.T)\n",
    "        recall = calculate_recall(this_model,train,test,user_idxs)\n",
    "        print('factors:{}, regularization:{}, recall:{:.2f}%'.format(this_model.factors,this_model.regularization,recall*100))\n",
    "        curves.append({'params': params,                       \n",
    "                       'recall@test': recall})\n",
    "    return curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factors:50, regularization:0, recall:9.23%\n",
      "factors:50, regularization:0.001, recall:9.23%\n",
      "factors:50, regularization:0.01, recall:9.23%\n",
      "factors:50, regularization:0.1, recall:9.30%\n",
      "factors:50, regularization:10.0, recall:9.04%\n",
      "factors:50, regularization:100.0, recall:3.45%\n",
      "factors:75, regularization:0, recall:9.23%\n",
      "factors:75, regularization:0.001, recall:9.23%\n",
      "factors:75, regularization:0.01, recall:9.23%\n",
      "factors:75, regularization:0.1, recall:9.30%\n",
      "factors:75, regularization:10.0, recall:9.04%\n",
      "factors:75, regularization:100.0, recall:3.45%\n",
      "factors:100, regularization:0, recall:9.23%\n",
      "factors:100, regularization:0.001, recall:9.23%\n",
      "factors:100, regularization:0.01, recall:9.23%\n",
      "factors:100, regularization:0.1, recall:9.30%\n",
      "factors:100, regularization:10.0, recall:9.04%\n",
      "factors:100, regularization:100.0, recall:3.45%\n"
     ]
    }
   ],
   "source": [
    "param_grids = {\n",
    "    'factors':[50,75,100],\n",
    "    'regularization':[0,1e-3,1e-2,1e-1,1e1,1e2]\n",
    "}\n",
    "curves = grid_search_learning_curve(model,train,test,param_grids,user_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': {'factors': 50, 'regularization': 0.1},\n",
       "  'recall@test': 0.09299740644683216},\n",
       " {'params': {'factors': 75, 'regularization': 0.1},\n",
       "  'recall@test': 0.09299740644683216},\n",
       " {'params': {'factors': 100, 'regularization': 0.1},\n",
       "  'recall@test': 0.09299740644683216},\n",
       " {'params': {'factors': 50, 'regularization': 0},\n",
       "  'recall@test': 0.09225639125602075},\n",
       " {'params': {'factors': 50, 'regularization': 0.001},\n",
       "  'recall@test': 0.09225639125602075},\n",
       " {'params': {'factors': 50, 'regularization': 0.01},\n",
       "  'recall@test': 0.09225639125602075},\n",
       " {'params': {'factors': 75, 'regularization': 0},\n",
       "  'recall@test': 0.09225639125602075},\n",
       " {'params': {'factors': 75, 'regularization': 0.001},\n",
       "  'recall@test': 0.09225639125602075},\n",
       " {'params': {'factors': 75, 'regularization': 0.01},\n",
       "  'recall@test': 0.09225639125602075},\n",
       " {'params': {'factors': 100, 'regularization': 0},\n",
       "  'recall@test': 0.09225639125602075},\n",
       " {'params': {'factors': 100, 'regularization': 0.001},\n",
       "  'recall@test': 0.09225639125602075},\n",
       " {'params': {'factors': 100, 'regularization': 0.01},\n",
       "  'recall@test': 0.09225639125602075},\n",
       " {'params': {'factors': 50, 'regularization': 10.0},\n",
       "  'recall@test': 0.09040385327899222},\n",
       " {'params': {'factors': 75, 'regularization': 10.0},\n",
       "  'recall@test': 0.09040385327899222},\n",
       " {'params': {'factors': 100, 'regularization': 10.0},\n",
       "  'recall@test': 0.09040385327899222},\n",
       " {'params': {'factors': 50, 'regularization': 100.0},\n",
       "  'recall@test': 0.03445720637273064},\n",
       " {'params': {'factors': 75, 'regularization': 100.0},\n",
       "  'recall@test': 0.03445720637273064},\n",
       " {'params': {'factors': 100, 'regularization': 100.0},\n",
       "  'recall@test': 0.03445720637273064}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(curves,key=lambda x:x['recall@test'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# At the beginning of the notebook\n",
    "## https://stackoverflow.com/questions/18786912/get-output-from-the-logging-module-in-ipython-notebook/28195348\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = implicit.als.AlternatingLeastSquares(factors=50,regularization=0.1,calculate_training_loss=True)\n",
    "model.fit(train64.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 工人智慧\n",
    "看看結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "def get_thumbnails(top_related_items, idx, idx_to_mid, N=10):\n",
    "#     row = sim[idx, :].A.ravel()\n",
    "    topNitems,scores = zip(*top_related_items.get_related(idx))\n",
    "    thumbs = []\n",
    "    for x in topNitems:         \n",
    "        response = requests.get('https://sketchfab.com/i/models/{}'.format(idx_to_mid[x])).json()\n",
    "        thumb = [x['url'] for x in response['thumbnails']['images'] if x['width'] == 200 and x['height']==200]\n",
    "        if not thumb:\n",
    "            print('no thumbnail')\n",
    "        else:\n",
    "            thumb = thumb[0]\n",
    "        thumbs.append(thumb)\n",
    "    return thumbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_to_mid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thumbs = get_thumbnails(top_related, idx=0, idx_to_mid=idx_to_mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_item(thumbs,N=5):\n",
    "    try: \n",
    "        print('原圖======')\n",
    "        thumb_html = '<img src='+ '\\\"'+thumbs[0]+'\\\">' \n",
    "    except TypeError:\n",
    "        print('oops, 找不到!!!')\n",
    "        thumb_html= \"\"\n",
    "    for url in thumbs[1:]:\n",
    "        if url:\n",
    "            thumb_html += \"\"\" <img style='width:120px;margin:0px;float:left;border:1px solid black;' src='{}' />\"\"\".format(url)            \n",
    "    return thumb_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(display_item(thumbs))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
