{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推薦模型\n",
    "\n",
    "## 前言(通常-->廢話)\n",
    "早餐去買三明治的時候，老闆娘總會好心的問說，要不要來杯紅茶。通常看在老闆娘的~~顏值~~誠意上，都會不爭氣的買了...推薦是針對原本客戶沒有預期到的結果，額外的跨售商品，或提示給用戶可能感興趣（喜歡）的東西（例如:買早餐時原本不會口渴，受到老闆娘的~~顏值~~影響才加購飲料的。）\n",
    "\n",
    "推薦方法火熱了這麼多年是因為在商業上有很實際的目的：\n",
    "\n",
    "1. 促進交易\n",
    "2. 加速決策\n",
    "\n",
    "簡單來說對商家來說，就是賺更多`$$`。對消費者來說可以從雜亂無章，一堆無用訊息裡面過濾有興趣的商品。在資訊過載的世界裡面，消費者無法一下子就能找到感興趣的東西。谷歌搜尋技法，在目的不明確的狀況下，沒辦法發揮功能。\n",
    "\n",
    "在網路時代，商家通常能夠快速的蒐集到用戶的購買/瀏覽/蒐藏紀錄，讓蒐集到的資訊，透過模型建立有機會，找到相似（相關性高）的商品來推薦（推播）。建構在模型上，消費者體驗的整體流程可以稱之為系統，系統面結合的範圍較大不在本文討論範圍（系統架構面本人也不懂，只懂簡單的幾種模型）。這一系列的文章，希望能紀錄自己對幾種熱門模型的理解。\n",
    "\n",
    "一般來說（就本人所知）有以下的算法框架\n",
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法框架\n",
    "\n",
    "* 協同過濾法(Collaborative Filtering)\n",
    "    - 相似度（最鄰近法-KNN)\n",
    "        - ubcf, ibcf\n",
    "    - 矩陣分解(Matrix Factorization)\n",
    "        - explict (implicit) ALS\n",
    "        - SVD, SVD++, SVDFeatures ...\n",
    "        - Learning to rank (BSR,WARP...)\n",
    "    - 深度學習\n",
    "        - DNN\n",
    "* 以內容最基礎(Content-based)\n",
    "_____________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最鄰近法(相似度)\n",
    "協同過濾法簡單說，就是透過群體的交易行為來推算，小王購買A,B,C的可能機會。透過群體關係，來推論誰和你的購買歷程相近...最大的特色是，不需要對商品/領域有專業知識即能有相當的準確度。其中最鄰近法(KNN)以考慮最相鄰的N人(物品)來計算，不算是一種[模型]，只是一種群眾給出的統計結果。沒有模型常見的訓練過程\n",
    "\n",
    "1. 定義cost function,\n",
    "2. 求得最佳參數\n",
    "3. 評估模型結果\n",
    "\n",
    "有以交易紀錄形成的資料如下，\n",
    "\n",
    "| |趙 |錢 |孫 | 李|\n",
    "|---|---|---|---|---|\n",
    "|牙刷|null|V|null|V|\n",
    "|牙膏|null|V|null|null|\n",
    "|腳踏車|null|null|V|V|\n",
    "|LED燈|V|null|null|V|\n",
    "|澡盆|V|V|null|V|\n",
    "\n",
    "以商品的角度來看，牙刷的交易紀錄`(0,1,0,1)`形成空間一組向量，可以計算與牙膏的相似度`(0,1,0,0)`。能建構所有商品的相似度表格\n",
    "\n",
    "$$\n",
    "cos(\\theta) = \\frac{r_{牙膏} \\cdot r_{牙刷}'}{\\lVert{r_{牙膏}}\\lVert \\lVert r_{牙刷}' \\lVert}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.70703125,  0.5       ,  0.5       ,  0.81640625],\n",
       "       [ 0.70703125,  1.        ,  0.        ,  0.        ,  0.57714844],\n",
       "       [ 0.5       ,  0.        ,  1.        ,  0.5       ,  0.40820312],\n",
       "       [ 0.5       ,  0.        ,  0.5       ,  1.        ,  0.81640625],\n",
       "       [ 0.81640625,  0.57714844,  0.40820312,  0.81640625,  1.        ]], dtype=float16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cos_similarity(rating,kind='ubcf',eps=1e-9):\n",
    "    if kind =='ubcf':\n",
    "        sim = np.dot(rating,rating.T) + eps\n",
    "    if kind =='ibcf':\n",
    "        sim = np.dot(rating.T,rating) + eps\n",
    "    norms = np.array([np.sqrt(np.diagonal(sim))])\n",
    "    return sim/norms/norms.T\n",
    "\n",
    "rating_t = np.array([\n",
    "    [0,1,0,1],\n",
    "    [0,1,0,0],\n",
    "    [0,0,1,1],\n",
    "    [1,0,0,1],\n",
    "    [1,1,0,1]\n",
    "  ])\n",
    "rating = rating_t.T\n",
    "sim_i = similarity(rating,kind='ibcf')\n",
    "sim_i.astype(np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有相似度矩陣後，就能針對每個用戶還沒買的商品作預測。\n",
    "\n",
    "$$\n",
    "\\hat{r_{ui}} = \\sum_{u'}Sim(u,u') \\cdot r_{u'i}\n",
    "$$\n",
    "or \n",
    "$$\n",
    "\\hat{r_{ui}} = \\sum_{i'} r_{ui'} \\cdot Sim(i,i')\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.31640625,  0.57714844,  0.90820312,  1.81640625,  1.81640625],\n",
       "       [ 2.5234375 ,  2.28515625,  0.90820312,  1.31640625,  2.39453125],\n",
       "       [ 0.5       ,  0.        ,  1.        ,  0.5       ,  0.40820312],\n",
       "       [ 2.81640625,  1.28417969,  2.40820312,  2.81640625,  3.04101562]], dtype=float16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ibcf = rating.dot(sim_i).astype(np.float16)\n",
    "score_ibcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以物品為基礎\n",
    "\n",
    "    - 牙膏澡盆相似度最高(0.816),牙膏牙刷相似度次高(0.7)\n",
    "    - 推薦孫：牙刷(0.5), LED燈(0.5) 已買腳踏車\n",
    "____________________    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推薦實例Sketchfab Demo\n",
    "\n",
    "我學習推薦系算法，除了阿撒不魯的網站論文看了一大堆，後來咀嚼思考後，覺得大概有87%的想法，源碼精神是來自於[DataPique](http://blog.ethanrosenthal.com/)大大的網站（其他的可謂~~垃圾?~~超越小弟~~腦弱~~的理解)，這個大大除了把最重要的幾種模型詳細推導一遍，更有趣的是作者(ethan)更自己爬了3DCAD的資料，蒐集第一手的客戶資料情況。真正公司會在網站後蒐集到的資料，通常都是客戶的隱式行為...(所以用這組資料來練習是最好不過的!)\n",
    "\n",
    "隱性資料(implicit data)是大部分人會在瀏覽網站的狀況，\n",
    "1. 好棒棒的點讚，\n",
    "2. 覺得很爛/很腦殘~~智缺~~/沒興趣，通常是不會有反應的（空值）。\n",
    "\n",
    "對真實世界來講，通常沒有好棒棒的評分資料，給你好棒棒的評分（像是啥鬼MovieLens影評資料...)。老實說我在聽mixerbox,spotify,netflix不好聽(看)就下一首(片)或關掉了。只有聽到好棒棒的影視/音樂，才會點讚讚。\n",
    "\n",
    "之後會模仿DataPique的作法，在這個[資料](https://github.com/ihongChen/PlayRecommendSystem/tree/master/rec-a-sketch)上利用KNN來實踐一次。人工智慧看看推薦結果如何...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料馬殺雞\n",
    "---最囉唆的就是資料清理了---\n",
    "\n",
    "* 資料通常很稀疏，要用`scipy.sparse`下面的稀疏矩陣來建構資料。\n",
    "    - [scipy lecture note](http://www.scipy-lectures.org/advanced/scipy_sparse/index.html)有教學說這咪一大堆的稀疏矩陣差異性(~~累死寶寶~~)。\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from KNNmodel import *\n",
    "from rec_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>mid</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D fanart Noel From Sora no Method</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "      <td>7ac1b40648fff523d7220a5d07b04d9b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D fanart Noel From Sora no Method</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "      <td>2b4ad286afe3369d39f1bb7aa2528bc7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3D fanart Noel From Sora no Method</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "      <td>1bf0993ebab175a896ac8003bed91b4b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3D fanart Noel From Sora no Method</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "      <td>6484211de8b9a023a7d9ab1641d22e7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3D fanart Noel From Sora no Method</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "      <td>1109ee298494fbd192e27878432c718a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            modelname                               mid  \\\n",
       "0  3D fanart Noel From Sora no Method  5dcebcfaedbd4e7b8a27bd1ae55f1ac3   \n",
       "1  3D fanart Noel From Sora no Method  5dcebcfaedbd4e7b8a27bd1ae55f1ac3   \n",
       "2  3D fanart Noel From Sora no Method  5dcebcfaedbd4e7b8a27bd1ae55f1ac3   \n",
       "3  3D fanart Noel From Sora no Method  5dcebcfaedbd4e7b8a27bd1ae55f1ac3   \n",
       "4  3D fanart Noel From Sora no Method  5dcebcfaedbd4e7b8a27bd1ae55f1ac3   \n",
       "\n",
       "                                uid  \n",
       "0  7ac1b40648fff523d7220a5d07b04d9b  \n",
       "1  2b4ad286afe3369d39f1bb7aa2528bc7  \n",
       "2  1bf0993ebab175a896ac8003bed91b4b  \n",
       "3  6484211de8b9a023a7d9ab1641d22e7c  \n",
       "4  1109ee298494fbd192e27878432c718a  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../rec-a-sketch/model_likes_anon.psv',\n",
    "                 sep='|',quotechar='\\\\',quoting=csv.QUOTE_MINIMAL)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "刪除部份重複資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelname    632832\n",
      "mid          632832\n",
      "uid          632832\n",
      "dtype: int64\n",
      "modelname    632677\n",
      "mid          632677\n",
      "uid          632677\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.count())\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "移除喜歡次數過少(`<5`)的用戶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting interactions info\n",
      "Number of rows: 62583\n",
      "Number of cols: 28806\n",
      "Sparsity: 0.04%\n",
      "Ending interactions info\n",
      "Number of rows: 13529\n",
      "Number of columns: 28707\n",
      "Sparsity: 0.14%\n"
     ]
    }
   ],
   "source": [
    "df = threshold_interaction(df,rowname='uid',colname='mid',row_min=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inter,uid_to_idx,idx_to_uid,mid_to_idx,idx_to_mid=df_to_spmatrix(df,'uid','mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## train,test split\n",
    "train,test, user_idxs = train_test_split(inter,split_count=1,fraction=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = train.T\n",
    "row_sums = mat.getnnz(axis=1).astype('int16')\n",
    "ab = mat.dot(mat.T)\n",
    "ab = ab.astype('float16')\n",
    "aa = np.repeat(row_sums,ab.getnnz(axis=1))\n",
    "bb = row_sums[ab.indices]\n",
    "sim = ab.copy()\n",
    "sim.data /= (aa+bb-ab.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(.dtype)\n",
    "sim.data = sim.data.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sim.setdiag(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ihong/anaconda3/lib/python3.5/site-packages/scipy/sparse/compressed.py:774: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity (jaccard) matrix built (ibcf), \n",
      "sparsity of similarity: 29.14 %\n"
     ]
    }
   ],
   "source": [
    "model_i = KNNmodel(train,kind='ibcf')\n",
    "model_i.jaccard_sim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立KNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_i = KNNmodel(train,kind='ibcf')\n",
    "model_i.jaccard_sim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ihong/anaconda3/lib/python3.5/site-packages/scipy/sparse/compressed.py:774: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity (jaccard) matrix built (ibcf), \n",
      "sparsity of similarity: 29.14 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28707/28707 [11:04<00:00, 43.23items/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ibcf rating matrix built...\n",
      "\n",
      "handling nan data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15939601/15939601 [00:14<00:00, 1131319.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers of rows : 13529\n",
      "numbers of cols: 28707\n",
      "sparsity of rating: 4.10 %\n",
      "save into *.rating attribute...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 109/13529 [00:00<00:12, 1082.94users/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity (jaccard) matrix built (ubcf), \n",
      "sparsity of similarity: 12.02 %\n",
      "-- start building topK user array...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13529/13529 [00:09<00:00, 1479.35users/s]\n",
      "  0%|          | 26/13529 [00:00<00:52, 259.21users/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- end building topK user array---\n",
      "start building prediction rating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13529/13529 [00:52<00:00, 259.92users/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ubcf rating matrix built...\n",
      "\n",
      "handling nan data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34255103/34255103 [00:29<00:00, 1156547.88it/s]\n",
      "  5%|▍         | 674/13529 [00:00<00:01, 6731.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers of rows : 13529\n",
      "numbers of cols: 28707\n",
      "sparsity of rating: 8.82 %\n",
      "save into *.rating attribute...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13529/13529 [00:02<00:00, 6583.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popular rating matrix built...\n",
      "\n",
      "handling nan data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1352900/1352900 [00:01<00:00, 1041182.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers of rows : 13529\n",
      "numbers of cols: 115\n",
      "sparsity of rating: 86.96 %\n",
      "save into *.rating attribute...\n"
     ]
    }
   ],
   "source": [
    "#ibcf\n",
    "model_i = KNNmodel(train,kind='ibcf')\n",
    "model_i.jaccard_sim()\n",
    "model_i.fit(topK=100,remove=True)\n",
    "# ## ubcf\n",
    "model_u = KNNmodel(train,kind='ubcf')\n",
    "model_u.jaccard_sim()\n",
    "model_u.fit(topK=100,remove=True)\n",
    "# ## popular\n",
    "model_p = KNNmodel(train,kind='popular')\n",
    "model_p.fit(topK=100,remove=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "topN = 10 \n",
    "topNarray = np.zeros((uids.shape[0],topN))\n",
    "for _idx,_id in enumerate(uids):\n",
    "    topNarray[_idx,:] = np.argsort(model_i.rating[_id,:].A,kind='heapsort')[:,:-topN-1:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------\n",
      "model: ibcf,\n",
      "topN: 10\n",
      "recall:5.88 %\n"
     ]
    }
   ],
   "source": [
    "pred_all = topNarray\n",
    "test_coo = test.tocoo()\n",
    "score = 0\n",
    "nonzero_rowsets = set(test_coo.row)\n",
    "for row,col,v in zip(test_coo.row,test_coo.col,test_coo.data):\n",
    "    if col in pred_all[row,]:\n",
    "        score += 1\n",
    "temp_recall = score/len(nonzero_rowsets)\n",
    "print(\"\\n-------------\")\n",
    "print(\"model: {},\\ntopN: {}\".format('ibcf', topN))\n",
    "print(\"recall:{:.2f} %\".format(score/len(test_coo.data) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------\n",
      "model: ubcf,\n",
      "topN: 10\n",
      "recall:15.49 %\n",
      "\n",
      "-------------\n",
      "model: popular,\n",
      "topN: 10\n",
      "recall:2.62 %\n"
     ]
    }
   ],
   "source": [
    "uids = np.arange(0,train.shape[0])\n",
    "\n",
    "predall_u = model_u.predict(uids,topN=10)\n",
    "model_u.evaluate(predall_u,test,method='recall') # 15.49 %\n",
    "\n",
    "# predall_i = model_i.predict(uids,topN=10)\n",
    "# model_i.evaluate(predall_i,test,method='precision') #recall:5.88\n",
    "\n",
    "predall_p = model_p.predict(uids,topN=10)\n",
    "model_p.evaluate(predall_p,test,method='recall') # 2.62 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------\n",
      "model: ubcf,\n",
      "topN: 10\n",
      "precision: 1.55 %\n",
      "\n",
      "-------------\n",
      "model: popular,\n",
      "topN: 10\n",
      "precision: 0.26 %\n"
     ]
    }
   ],
   "source": [
    "model_u.evaluate(predall_u,test,method='precision')\n",
    "model_p.evaluate(predall_p,test,method='precision')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
