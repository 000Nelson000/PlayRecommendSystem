{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting implicit\n",
      "  Downloading implicit-0.2.6.tar.gz (260kB)\n",
      "\u001b[K    100% |████████████████████████████████| 266kB 2.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ihong/anaconda3/lib/python3.5/site-packages (from implicit)\n",
      "Requirement already satisfied: scipy>=0.16 in /home/ihong/anaconda3/lib/python3.5/site-packages (from implicit)\n",
      "Building wheels for collected packages: implicit\n",
      "  Running setup.py bdist_wheel for implicit ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/ihong/.cache/pip/wheels/b8/72/24/e572345d776fb340193d0dd3b902a9f81ad39de7b9d61387ef\n",
      "Successfully built implicit\n",
      "Installing collected packages: implicit\n",
      "Successfully installed implicit-0.2.6\n"
     ]
    }
   ],
   "source": [
    "!pip install implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "import pickle\n",
    "import csv\n",
    "import implicit\n",
    "import itertools\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid|type|value\r\n",
      "5dcebcfaedbd4e7b8a27bd1ae55f1ac3|category|Characters\r\n",
      "5dcebcfaedbd4e7b8a27bd1ae55f1ac3|category|Gaming\r\n",
      "5dcebcfaedbd4e7b8a27bd1ae55f1ac3|tag|3dsmax\r\n",
      "5dcebcfaedbd4e7b8a27bd1ae55f1ac3|tag|noel\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 ./rec-a-sketch/data/model_feats.psv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>mid</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D fanart Noel From Sora no Method</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "      <td>7ac1b40648fff523d7220a5d07b04d9b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D fanart Noel From Sora no Method</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "      <td>2b4ad286afe3369d39f1bb7aa2528bc7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3D fanart Noel From Sora no Method</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "      <td>1bf0993ebab175a896ac8003bed91b4b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3D fanart Noel From Sora no Method</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "      <td>6484211de8b9a023a7d9ab1641d22e7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3D fanart Noel From Sora no Method</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "      <td>1109ee298494fbd192e27878432c718a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            modelname                               mid  \\\n",
       "0  3D fanart Noel From Sora no Method  5dcebcfaedbd4e7b8a27bd1ae55f1ac3   \n",
       "1  3D fanart Noel From Sora no Method  5dcebcfaedbd4e7b8a27bd1ae55f1ac3   \n",
       "2  3D fanart Noel From Sora no Method  5dcebcfaedbd4e7b8a27bd1ae55f1ac3   \n",
       "3  3D fanart Noel From Sora no Method  5dcebcfaedbd4e7b8a27bd1ae55f1ac3   \n",
       "4  3D fanart Noel From Sora no Method  5dcebcfaedbd4e7b8a27bd1ae55f1ac3   \n",
       "\n",
       "                                uid  \n",
       "0  7ac1b40648fff523d7220a5d07b04d9b  \n",
       "1  2b4ad286afe3369d39f1bb7aa2528bc7  \n",
       "2  1bf0993ebab175a896ac8003bed91b4b  \n",
       "3  6484211de8b9a023a7d9ab1641d22e7c  \n",
       "4  1109ee298494fbd192e27878432c718a  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./rec-a-sketch/data/model_likes_anon.psv',\n",
    "                 sep='|', quoting=csv.QUOTE_MINIMAL,\n",
    "                 quotechar='\\\\')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated rows: 155\n",
      "That's weird - let's just drop them\n"
     ]
    }
   ],
   "source": [
    "print('Duplicated rows: ' + str(df.duplicated().sum()))\n",
    "print('That\\'s weird - let\\'s just drop them')\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>mid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7ac1b40648fff523d7220a5d07b04d9b</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2b4ad286afe3369d39f1bb7aa2528bc7</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1bf0993ebab175a896ac8003bed91b4b</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6484211de8b9a023a7d9ab1641d22e7c</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1109ee298494fbd192e27878432c718a</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                uid                               mid\n",
       "0  7ac1b40648fff523d7220a5d07b04d9b  5dcebcfaedbd4e7b8a27bd1ae55f1ac3\n",
       "1  2b4ad286afe3369d39f1bb7aa2528bc7  5dcebcfaedbd4e7b8a27bd1ae55f1ac3\n",
       "2  1bf0993ebab175a896ac8003bed91b4b  5dcebcfaedbd4e7b8a27bd1ae55f1ac3\n",
       "3  6484211de8b9a023a7d9ab1641d22e7c  5dcebcfaedbd4e7b8a27bd1ae55f1ac3\n",
       "4  1109ee298494fbd192e27878432c718a  5dcebcfaedbd4e7b8a27bd1ae55f1ac3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['uid', 'mid']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 62583\n",
      "Number of models: 28806\n",
      "Sparsity: 0.035%\n"
     ]
    }
   ],
   "source": [
    "n_users = df.uid.unique().shape[0]\n",
    "n_items = df.mid.unique().shape[0]\n",
    "\n",
    "print('Number of users: {}'.format(n_users))\n",
    "print('Number of models: {}'.format(n_items))\n",
    "print('Sparsity: {:4.3f}%'.format(float(df.shape[0]) / float(n_users*n_items) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def threshold_likes(df, uid_min, mid_min):\n",
    "    n_users = df.uid.unique().shape[0]\n",
    "    n_items = df.mid.unique().shape[0]\n",
    "    sparsity = float(df.shape[0]) / float(n_users*n_items) * 100\n",
    "    print('Starting likes info')\n",
    "    print('Number of users: {}'.format(n_users))\n",
    "    print('Number of models: {}'.format(n_items))\n",
    "    print('Sparsity: {:4.3f}%'.format(sparsity))\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        starting_shape = df.shape[0]\n",
    "        mid_counts = df.groupby('uid').mid.count()\n",
    "        df = df[~df.uid.isin(mid_counts[mid_counts < mid_min].index.tolist())]\n",
    "        uid_counts = df.groupby('mid').uid.count()\n",
    "        df = df[~df.mid.isin(uid_counts[uid_counts < uid_min].index.tolist())]\n",
    "        ending_shape = df.shape[0]\n",
    "        if starting_shape == ending_shape:\n",
    "            done = True\n",
    "    \n",
    "    assert(df.groupby('uid').mid.count().min() >= mid_min)\n",
    "    assert(df.groupby('mid').uid.count().min() >= uid_min)\n",
    "    \n",
    "    n_users = df.uid.unique().shape[0]\n",
    "    n_items = df.mid.unique().shape[0]\n",
    "    sparsity = float(df.shape[0]) / float(n_users*n_items) * 100\n",
    "    print('Ending likes info')\n",
    "    print('Number of users: {}'.format(n_users))\n",
    "    print('Number of models: {}'.format(n_items))\n",
    "    print('Sparsity: {:4.3f}%'.format(sparsity))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting likes info\n",
      "Number of users: 62583\n",
      "Number of models: 28806\n",
      "Sparsity: 0.035%\n",
      "Ending likes info\n",
      "Number of users: 15274\n",
      "Number of models: 25655\n",
      "Sparsity: 0.140%\n"
     ]
    }
   ],
   "source": [
    "df_lim = threshold_likes(df, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>mid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2b4ad286afe3369d39f1bb7aa2528bc7</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1bf0993ebab175a896ac8003bed91b4b</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1109ee298494fbd192e27878432c718a</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8626c70d4b85af57804a8fc1173cbbe0</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>e1527fdfa8782e70d499e177efc28605</td>\n",
       "      <td>5dcebcfaedbd4e7b8a27bd1ae55f1ac3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                uid                               mid\n",
       "1  2b4ad286afe3369d39f1bb7aa2528bc7  5dcebcfaedbd4e7b8a27bd1ae55f1ac3\n",
       "2  1bf0993ebab175a896ac8003bed91b4b  5dcebcfaedbd4e7b8a27bd1ae55f1ac3\n",
       "4  1109ee298494fbd192e27878432c718a  5dcebcfaedbd4e7b8a27bd1ae55f1ac3\n",
       "6  8626c70d4b85af57804a8fc1173cbbe0  5dcebcfaedbd4e7b8a27bd1ae55f1ac3\n",
       "7  e1527fdfa8782e70d499e177efc28605  5dcebcfaedbd4e7b8a27bd1ae55f1ac3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create mappings\n",
    "mid_to_idx = {}\n",
    "idx_to_mid = {}\n",
    "for (idx, mid) in enumerate(df_lim.mid.unique().tolist()):\n",
    "    mid_to_idx[mid] = idx\n",
    "    idx_to_mid[idx] = mid\n",
    "    \n",
    "uid_to_idx = {}\n",
    "idx_to_uid = {}\n",
    "for (idx, uid) in enumerate(df_lim.uid.unique().tolist()):\n",
    "    uid_to_idx[uid] = idx\n",
    "    idx_to_uid[idx] = uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_ids(row, mapper):\n",
    "    return mapper[row]\n",
    "I = df_lim.uid.apply(map_ids, args=[uid_to_idx]).as_matrix()\n",
    "J = df_lim.mid.apply(map_ids, args=[mid_to_idx]).as_matrix()\n",
    "V = np.ones(I.shape[0])\n",
    "likes = sparse.coo_matrix((V, (I, J)), dtype=np.float64)\n",
    "likes = likes.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<15274x25655 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 547477 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(ratings, split_count, fraction=None):\n",
    "    \"\"\"\n",
    "    Split recommendation data into train and test sets\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    ratings : scipy.sparse matrix\n",
    "        Interactions between users and items.\n",
    "    split_count : int\n",
    "        Number of user-item-interactions per user to move\n",
    "        from training to test set.\n",
    "    fractions : float\n",
    "        Fraction of users to split off some of their\n",
    "        interactions into test set. If None, then all \n",
    "        users are considered.\n",
    "    \"\"\"\n",
    "    # Note: likely not the fastest way to do things below.\n",
    "    train = ratings.copy().tocoo()\n",
    "    test = sparse.lil_matrix(train.shape)\n",
    "    \n",
    "    if fraction:\n",
    "        try:\n",
    "            user_index = np.random.choice(\n",
    "                np.where(np.bincount(train.row) >= split_count * 2)[0], \n",
    "                replace=False,\n",
    "                size=np.int32(np.floor(fraction * train.shape[0]))\n",
    "            ).tolist()\n",
    "        except:\n",
    "            print(('Not enough users with > {} '\n",
    "                  'interactions for fraction of {}')\\\n",
    "                  .format(2*k, fraction))\n",
    "            raise\n",
    "    else:\n",
    "        user_index = range(train.shape[0])\n",
    "        \n",
    "    train = train.tolil()\n",
    "\n",
    "    for user in user_index:\n",
    "        test_ratings = np.random.choice(ratings.getrow(user).indices, \n",
    "                                        size=split_count, \n",
    "                                        replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        # These are just 1.0 right now\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "   \n",
    "    \n",
    "    # Test and training are truly disjoint\n",
    "    assert(train.multiply(test).nnz == 0)\n",
    "    return train.tocsr(), test.tocsr(), user_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test, user_index = train_test_split(likes, 5, fraction=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Implicit pack\n",
    "how to use it correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<15274x25655 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 532207 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    }
   ],
   "source": [
    "import implicit\n",
    "\n",
    "# initialize a model\n",
    "model = implicit.als.AlternatingLeastSquares(factors=50)\n",
    "\n",
    "# train the model on a sparse matrix of item/user/confidence weights\n",
    "model.fit(train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_user_data = train.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# recommend items for a user\n",
    "user_items = item_user_data.T.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0], dtype=int32),\n",
       " array([  63,  404,  464,  821, 8771], dtype=int32))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0,].nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recommendations = model.recommend(0, train)\n",
    "\n",
    "# find related items\n",
    "# related = model.similar_items(itemid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.17874765970827688),\n",
       " (28, 0.17552668233050572),\n",
       " (18, 0.15293313099831193),\n",
       " (31, 0.13600750348366894),\n",
       " (5, 0.13237937997834803),\n",
       " (11, 0.1201389359256903),\n",
       " (44, 0.11827689632636058),\n",
       " (38, 0.11818920329167953),\n",
       " (4, 0.11171901526749041),\n",
       " (45, 0.1080136838574019)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1.0),\n",
       " (28, 0.90333072368321932),\n",
       " (8241, 0.84987757626366378),\n",
       " (170, 0.79798833099372068),\n",
       " (19522, 0.79415495886846976),\n",
       " (45, 0.79307671410071368),\n",
       " (22697, 0.76807114676834809),\n",
       " (53, 0.72916716302822027),\n",
       " (38, 0.71163194328747903),\n",
       " (89, 0.69658239620330498)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_items(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "Grid-Search for hyper-parameters :\n",
    "\n",
    "1. `num_factors` : the numbers of latent factors\n",
    "2. `regularization`: Scale of regularizer for both user,item\n",
    "3. `alpha`: confidence scaling term\n",
    "4. `iteration`: iteration numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def calculate_mse(model, ratings, user_index=None):\n",
    "    preds = model.predict_for_customers()\n",
    "    if user_index:\n",
    "        return mean_squared_error(ratings[user_index, :].toarray().ravel(),\n",
    "                                  preds[user_index, :].ravel())\n",
    "    \n",
    "    return mean_squared_error(ratings.toarray().ravel(),\n",
    "                              preds.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision_at_k(model, ratings, k=5, user_index=None):\n",
    "    if not user_index:\n",
    "        user_index = range(ratings.shape[0])\n",
    "    ratings = ratings.tocsr()\n",
    "    precisions = []\n",
    "    # Note: line below may become infeasible for large datasets.\n",
    "    predictions = model.predict_for_customers()\n",
    "    for user in user_index:\n",
    "        # In case of large dataset, compute predictions row-by-row like below\n",
    "        # predictions = np.array([model.predict(row, i) for i in xrange(ratings.shape[1])])\n",
    "        top_k = np.argsort(-predictions[user, :])[:k]\n",
    "        labels = ratings.getrow(user).indices\n",
    "        precision = float(len(set(top_k) & set(labels))) / float(k)\n",
    "        precisions.append(precision)\n",
    "    return np.mean(precisions)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_log(row, header=False, spacing=12):\n",
    "    top = ''\n",
    "    middle = ''\n",
    "    bottom = ''\n",
    "    for r in row:\n",
    "        top += '+{}'.format('-'*spacing)\n",
    "        if isinstance(r, str):\n",
    "            middle += '| {0:^{1}} '.format(r, spacing-2)\n",
    "        elif isinstance(r, int):\n",
    "            middle += '| {0:^{1}} '.format(r, spacing-2)\n",
    "        elif isinstance(r, float):\n",
    "            middle += '| {0:^{1}.5f} '.format(r, spacing-2)\n",
    "        bottom += '+{}'.format('='*spacing)\n",
    "    top += '+'\n",
    "    middle += '|'\n",
    "    bottom += '+'\n",
    "    if header:\n",
    "        print(top)\n",
    "        print(middle)\n",
    "        print(bottom)\n",
    "    else:\n",
    "        print(middle)\n",
    "        print(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learning_curve(model, train, test, epochs, k=5, user_index=None):\n",
    "    if not user_index:\n",
    "        user_index = range(train.shape[0])\n",
    "    prev_epoch = 0\n",
    "    train_precision = []\n",
    "    train_mse = []\n",
    "    test_precision = []\n",
    "    test_mse = []\n",
    "    \n",
    "    headers = ['epochs', 'p@k train', 'p@k test',\n",
    "               'mse train', 'mse test']\n",
    "    print_log(headers, header=True)\n",
    "    \n",
    "    for epoch in epochs:\n",
    "        model.iterations = epoch - prev_epoch\n",
    "        if not hasattr(model, 'user_vectors'):\n",
    "            model.fit(train)\n",
    "        else:\n",
    "            model.fit_partial(train)\n",
    "        train_mse.append(calculate_mse(model, train, user_index))\n",
    "        train_precision.append(precision_at_k(model, train, k, user_index))\n",
    "        test_mse.append(calculate_mse(model, test, user_index))\n",
    "        test_precision.append(precision_at_k(model, test, k, user_index))\n",
    "        row = [epoch, train_precision[-1], test_precision[-1],\n",
    "               train_mse[-1], test_mse[-1]]\n",
    "        print_log(row)\n",
    "        prev_epoch = epoch\n",
    "    return model, train_precision, train_mse, test_precision, test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search_learning_curve(base_model, train, test, param_grid,\n",
    "                               user_index=None, patk=5, epochs=range(2, 40, 2)):\n",
    "    \"\"\"\n",
    "    \"Inspired\" (stolen) from sklearn gridsearch\n",
    "    https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_search.py\n",
    "    \"\"\"\n",
    "    curves = []\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    for v in itertools.product(*values):\n",
    "        params = dict(zip(keys, v))\n",
    "        this_model = copy.deepcopy(base_model)\n",
    "        print_line = []\n",
    "        for k, v in params.items():\n",
    "            setattr(this_model, k, v)\n",
    "            print_line.append((k, v))\n",
    "\n",
    "        print(' | '.join('{}: {}'.format(k, v) for (k, v) in print_line))\n",
    "        _, train_patk, train_mse, test_patk, test_mse = learning_curve(this_model, train, test,\n",
    "                                                                epochs, k=patk, user_index=user_index)\n",
    "        curves.append({'params': params,\n",
    "                       'patk': {'train': train_patk, 'test': test_patk},\n",
    "                       'mse': {'train': train_mse, 'test': test_mse}})\n",
    "    return curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO grid-search(!!! VERY SLOW --- take several days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'num_factors': [10, 20, 40, 80, 120],\n",
    "              'regularization': [0.0, 1e-5, 1e-3, 1e-1, 1e1, 1e2],\n",
    "              'alpha': [1, 10, 50, 100, 500, 1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!export OPENBLAS_NUM_THREADS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    }
   ],
   "source": [
    "base_model = implicit.als.AlternatingLeastSquares()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': [1, 10, 50, 100, 500, 1000],\n",
       " 'num_factors': [10, 20, 40, 80, 120],\n",
       " 'regularization': [0.0, 1e-05, 0.001, 0.1, 10.0, 100.0]}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curves = grid_search_learning_curve(base_model, train, test,\n",
    "                                    param_grid,\n",
    "                                    user_index=user_index,\n",
    "                                    patk=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization: 0.0 | num_factors: 10 | alpha: 1\n",
      "+------------+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  | mse train  |  mse test  |\n",
      "+============+============+============+============+============+\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AlternatingLeastSquares' object has no attribute 'predict_for_customers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-e17fc1f71c52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                                     \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                     \u001b[0muser_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                                     patk=5)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-84-9ec89115ec02>\u001b[0m in \u001b[0;36mgrid_search_learning_curve\u001b[0;34m(base_model, train, test, param_grid, user_index, patk, epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' | '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprint_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         _, train_patk, train_mse, test_patk, test_mse = learning_curve(this_model, train, test,\n\u001b[0;32m---> 19\u001b[0;31m                                                                 epochs, k=patk, user_index=user_index)\n\u001b[0m\u001b[1;32m     20\u001b[0m         curves.append({'params': params,\n\u001b[1;32m     21\u001b[0m                        \u001b[0;34m'patk'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_patk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_patk\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-4a43942b2752>\u001b[0m in \u001b[0;36mlearning_curve\u001b[0;34m(model, train, test, epochs, k, user_index)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtrain_mse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mtrain_precision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_at_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtest_mse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-7769df4d0140>\u001b[0m in \u001b[0;36mcalculate_mse\u001b[0;34m(model, ratings, user_index)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_for_customers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         return mean_squared_error(ratings[user_index, :].toarray().ravel(),\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AlternatingLeastSquares' object has no attribute 'predict_for_customers'"
     ]
    }
   ],
   "source": [
    "curves = grid_search_learning_curve(base_model, train, test,\n",
    "                                    param_grid,\n",
    "                                    user_index=user_index,\n",
    "                                    patk=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_base = implicit.als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
