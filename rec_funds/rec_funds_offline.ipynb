{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pypyodbc\n",
    "import sys\n",
    "import pandas as pd \n",
    "import time\n",
    "# sys.path.append('../')\n",
    "from KNNmodel import *\n",
    "from rec_helper import *\n",
    "from tqdm import tqdm\n",
    "import scipy.sparse as sp          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con = pypyodbc.connect(\"DRIVER={SQL Server};SERVER=dbm_public;UID=sa;PWD=01060728;DATABASE=project2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"select * from 基金推薦_近二年申購_憑證歸戶 \",con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>身分證字號</th>\n",
       "      <th>憑證</th>\n",
       "      <th>基金代碼</th>\n",
       "      <th>商品投資屬性</th>\n",
       "      <th>申購登錄日</th>\n",
       "      <th>扣款次數</th>\n",
       "      <th>申購扣款金額_台幣</th>\n",
       "      <th>國內外基金註記</th>\n",
       "      <th>aum基金型態別</th>\n",
       "      <th>投資型態</th>\n",
       "      <th>投資地區</th>\n",
       "      <th>型態別</th>\n",
       "      <th>aum型態別</th>\n",
       "      <th>aum計算類別</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G2723186890</td>\n",
       "      <td>120J0W41600368</td>\n",
       "      <td>J0W</td>\n",
       "      <td>RR3</td>\n",
       "      <td>20160701</td>\n",
       "      <td>1</td>\n",
       "      <td>234180.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B</td>\n",
       "      <td>b.單筆申購</td>\n",
       "      <td>a.境外基金</td>\n",
       "      <td>b.債券型</td>\n",
       "      <td>b.債券型</td>\n",
       "      <td>國外債券型</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1235025000</td>\n",
       "      <td>136317C1700029</td>\n",
       "      <td>317</td>\n",
       "      <td>RR3</td>\n",
       "      <td>20170811</td>\n",
       "      <td>1</td>\n",
       "      <td>496793.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B</td>\n",
       "      <td>b.單筆申購</td>\n",
       "      <td>b.國內基金</td>\n",
       "      <td>b.債券型</td>\n",
       "      <td>b.債券型</td>\n",
       "      <td>國內債券型</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F2778691990</td>\n",
       "      <td>18463Z51700045</td>\n",
       "      <td>63Z</td>\n",
       "      <td>RR5</td>\n",
       "      <td>20171011</td>\n",
       "      <td>3</td>\n",
       "      <td>13571.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E</td>\n",
       "      <td>a.定時定額</td>\n",
       "      <td>a.境外基金</td>\n",
       "      <td>a.股票型</td>\n",
       "      <td>a.股票型</td>\n",
       "      <td>國外股票型</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D2724924750</td>\n",
       "      <td>023Y3801700178</td>\n",
       "      <td>Y38</td>\n",
       "      <td>RR4</td>\n",
       "      <td>20171027</td>\n",
       "      <td>1</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E</td>\n",
       "      <td>b.單筆申購</td>\n",
       "      <td>a.境外基金</td>\n",
       "      <td>a.股票型</td>\n",
       "      <td>a.股票型</td>\n",
       "      <td>國外股票型</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D2721254300</td>\n",
       "      <td>013J1F11600058</td>\n",
       "      <td>J1F</td>\n",
       "      <td>RR3</td>\n",
       "      <td>20160504</td>\n",
       "      <td>4</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>W</td>\n",
       "      <td>a.定時定額</td>\n",
       "      <td>a.境外基金</td>\n",
       "      <td>d.其他型</td>\n",
       "      <td>d.平衡型</td>\n",
       "      <td>國外其他型</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         身分證字號              憑證 基金代碼 商品投資屬性     申購登錄日  扣款次數  申購扣款金額_台幣  \\\n",
       "0  G2723186890  120J0W41600368  J0W    RR3  20160701     1   234180.8   \n",
       "1  A1235025000  136317C1700029  317    RR3  20170811     1   496793.0   \n",
       "2  F2778691990  18463Z51700045  63Z    RR5  20171011     3    13571.1   \n",
       "3  D2724924750  023Y3801700178  Y38    RR4  20171027     1   500000.0   \n",
       "4  D2721254300  013J1F11600058  J1F    RR3  20160504     4  2000000.0   \n",
       "\n",
       "   國內外基金註記 aum基金型態別    投資型態    投資地區    型態別 aum型態別 aum計算類別  \n",
       "0      1.0        B  b.單筆申購  a.境外基金  b.債券型  b.債券型   國外債券型  \n",
       "1      0.0        B  b.單筆申購  b.國內基金  b.債券型  b.債券型   國內債券型  \n",
       "2      1.0        E  a.定時定額  a.境外基金  a.股票型  a.股票型   國外股票型  \n",
       "3      1.0        E  b.單筆申購  a.境外基金  a.股票型  a.股票型   國外股票型  \n",
       "4      1.0        W  a.定時定額  a.境外基金  d.其他型  d.平衡型   國外其他型  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting interactions info\n",
      "Number of rows: 35122\n",
      "Number of cols: 2059\n",
      "Sparsity: 0.20%\n",
      "Ending interactions info\n",
      "Number of rows: 19748\n",
      "Number of columns: 2028\n",
      "Sparsity: 0.32%\n"
     ]
    }
   ],
   "source": [
    "# 建立u-i 矩陣 至少買過一檔基金\n",
    "df_gt2 = threshold_interaction(df,rowname='身分證字號',colname='基金代碼',row_min=1,col_min=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "purchased_ui, userid_to_idx, \\\n",
    "    idx_to_userid, itemid_to_idx,idx_to_itemid  = df_to_spmatrix(df_gt2,'身分證字號','基金代碼',binary=False)\n",
    "train,test, user_idxs = train_test_split(purchased_ui,split_count=1,fraction=0.2)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN model \n",
    "ubcf/ibcf/popular \n",
    "### jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity (jaccard) matrix built (ibcf), \n",
      "sparsity of similarity: 8.20 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 2028/2028 [00:32<00:00, 61.95items/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ibcf rating matrix built...\n",
      "\n",
      "handling nan data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 12315828/12315828 [00:09<00:00, 1244660.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers of rows : 19748\n",
      "numbers of cols: 2028\n",
      "sparsity of rating: 30.75 %\n",
      "save into *.rating attribute...\n",
      "\n",
      "***\n",
      "time cost for ibcf:53.8s\n"
     ]
    }
   ],
   "source": [
    "## ibcf\n",
    "t1 = time.time()\n",
    "model_i = KNNmodel(train,kind='ibcf')\n",
    "model_i.jaccard_sim()\n",
    "model_i.fit(topK=100,remove=True)\n",
    "t2 = time.time()\n",
    "dt_ibcf = t2-t1\n",
    "print('\\n***')\n",
    "print('time cost for ibcf:{:.1f}s'.format(dt_ibcf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity (jaccard) matrix built (ubcf), \n",
      "sparsity of similarity: 11.19 %\n",
      "-- start building topK user array...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 19748/19748 [00:16<00:00, 1232.06users/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- end building topK user array---\n",
      "start building prediction rating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 19748/19748 [00:32<00:00, 616.95users/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ubcf rating matrix built...\n",
      "\n",
      "handling nan data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 2230362/2230362 [00:01<00:00, 1222353.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers of rows : 19748\n",
      "numbers of cols: 2028\n",
      "sparsity of rating: 5.57 %\n",
      "save into *.rating attribute...\n",
      "\n",
      "***\n",
      "time cost for ubcf:72.9s\n"
     ]
    }
   ],
   "source": [
    "## ubcf -- jaccard\n",
    "t1 = time.time()\n",
    "model_u = KNNmodel(train,kind='ubcf')\n",
    "model_u.jaccard_sim()\n",
    "model_u.fit(topK=100,remove=True)\n",
    "t2 = time.time()\n",
    "dt_ubcf = t2-t1\n",
    "print('\\n***')\n",
    "print('time cost for ubcf:{:.1f}s'.format(dt_ubcf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 19748/19748 [00:03<00:00, 6331.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popular rating matrix built...\n",
      "\n",
      "handling nan data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 1974800/1974800 [00:01<00:00, 1194319.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers of rows : 19748\n",
      "numbers of cols: 535\n",
      "sparsity of rating: 18.69 %\n",
      "save into *.rating attribute...\n",
      "\n",
      "***\n",
      "time cost for popular:5.7s\n"
     ]
    }
   ],
   "source": [
    "## popular \n",
    "t1 = time.time()\n",
    "model_p = KNNmodel(train,kind='popular')\n",
    "model_p.fit(topK=100,remove=True)\n",
    "t2 = time.time()\n",
    "dt_pop = t2-t1\n",
    "print('\\n***')\n",
    "print('time cost for popular:{:.1f}s'.format(dt_pop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* UBCF / IBCF / popular\n",
    "## cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\scipy\\sparse\\compressed.py:774: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity (cosine) matrix build (ibcf), \n",
      "sparsity of similarity: 8.25 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 2028/2028 [00:35<00:00, 56.65items/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ibcf rating matrix built...\n",
      "\n",
      "handling nan data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 14208785/14208785 [00:10<00:00, 1292773.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers of rows : 19748\n",
      "numbers of cols: 2028\n",
      "sparsity of rating: 35.48 %\n",
      "save into *.rating attribute...\n",
      "\n",
      "***\n",
      "time cost for ibcf:60.2s,(cosine)\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "model_i_cos = KNNmodel(train,kind='ibcf')\n",
    "model_i_cos.cosine_sim()\n",
    "model_i_cos.fit(topK=100,remove=True)\n",
    "t2 = time.time()\n",
    "dt_ibcf = t2-t1\n",
    "print('\\n***')\n",
    "print('time cost for ibcf:{:.1f}s,(cosine)'.format(dt_ibcf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity (cosine) matrix build (ubcf), \n",
      "sparsity of similarity: 11.20 %\n",
      "-- start building topK user array...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 19748/19748 [00:17<00:00, 1145.11users/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- end building topK user array---\n",
      "start building prediction rating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 19748/19748 [00:32<00:00, 611.33users/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ubcf rating matrix built...\n",
      "\n",
      "handling nan data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 2513476/2513476 [00:02<00:00, 1174008.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers of rows : 19748\n",
      "numbers of cols: 2028\n",
      "sparsity of rating: 6.28 %\n",
      "save into *.rating attribute...\n",
      "\n",
      "***\n",
      "time cost for ubcf:54.9s\n"
     ]
    }
   ],
   "source": [
    "## ubcf\n",
    "t1 = time.time()\n",
    "model_u_cos = KNNmodel(train,kind='ubcf')\n",
    "model_u_cos.cosine_sim()\n",
    "model_u_cos.fit(topK=100,remove=True)\n",
    "t2 = time.time()\n",
    "dt_ubcf = t2-t1\n",
    "print('\\n***')\n",
    "print('time cost for ubcf:{:.1f}s'.format(dt_ubcf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* bm25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 2028/2028 [00:32<00:00, 62.27items/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ibcf rating matrix built...\n",
      "\n",
      "handling nan data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 11350905/11350905 [00:08<00:00, 1320524.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers of rows : 19748\n",
      "numbers of cols: 2028\n",
      "sparsity of rating: 28.34 %\n",
      "save into *.rating attribute...\n",
      "\n",
      "***\n",
      "time cost for ibcf:51.4s\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "model_i_bm25 = KNNmodel(train,kind='ibcf')\n",
    "model_i_bm25.bm25_sim()\n",
    "model_i_bm25.fit(topK=100,remove=True)\n",
    "t2 = time.time()\n",
    "dt_ibcf = t2-t1\n",
    "print('\\n***')\n",
    "print('time cost for ibcf:{:.1f}s'.format(dt_ibcf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- start building topK user array...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 19748/19748 [00:17<00:00, 1141.20users/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- end building topK user array---\n",
      "start building prediction rating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 19748/19748 [00:31<00:00, 622.29users/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ubcf rating matrix built...\n",
      "\n",
      "handling nan data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 2011461/2011461 [00:01<00:00, 1212820.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers of rows : 19748\n",
      "numbers of cols: 2028\n",
      "sparsity of rating: 5.02 %\n",
      "save into *.rating attribute...\n",
      "\n",
      "***\n",
      "time cost for ubcf:53.7s\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "model_u_bm25 = KNNmodel(train,kind='ubcf')\n",
    "model_u_bm25.bm25_sim(K1=10,B=1)\n",
    "model_u_bm25.fit(topK=100,remove=True)\n",
    "t2 = time.time()\n",
    "dt_ubcf = t2-t1\n",
    "print('\\n***')\n",
    "print('time cost for ubcf:{:.1f}s'.format(dt_ubcf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評估模型 \n",
    "    - recall/ precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======jaccard similarity =====\n",
      "\n",
      "-------------\n",
      "model: ubcf,\n",
      "topN: 10\n",
      "recall:27.91 %\n",
      "\n",
      "-------------\n",
      "model: ibcf,\n",
      "topN: 10\n",
      "recall:13.67 %\n",
      "\n",
      "-------------\n",
      "model: popular,\n",
      "topN: 10\n",
      "recall:20.99 %\n"
     ]
    }
   ],
   "source": [
    "uids = np.arange(0,train.shape[0])\n",
    "print('======jaccard similarity =====')\n",
    "predall_u = model_u.predict(uids,topN=10) # np array (itemidx)\n",
    "model_u.evaluate(predall_u,test,method='recall') # 29.27\n",
    "\n",
    "predall_i = model_i.predict(uids,topN=10) #nparray (itemidx)\n",
    "model_i.evaluate(predall_i,test,method='recall') # 12.71 \n",
    "\n",
    "predall_p = model_p.predict(uids,topN=10) #nparray (itemidx)\n",
    "model_p.evaluate(predall_p,test,method='recall') # 20.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====cosine similarity======\n",
      "\n",
      "-------------\n",
      "model: ubcf,\n",
      "topN: 10\n",
      "recall:27.42 %\n",
      "\n",
      "-------------\n",
      "model: ibcf,\n",
      "topN: 10\n",
      "recall:1.54 %\n"
     ]
    }
   ],
   "source": [
    "print('=====cosine similarity======')\n",
    "predall_u_cos = model_u_cos.predict(uids,topN=10)\n",
    "model_u_cos.evaluate(predall_u_cos,test,method='recall')\n",
    "\n",
    "predall_i_cos = model_i_cos.predict(uids,topN=10)\n",
    "model_i_cos.evaluate(predall_i_cos,test,method='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======bm25 similarity =====\n",
      "\n",
      "-------------\n",
      "model: ubcf,\n",
      "topN: 10\n",
      "recall:27.48 %\n",
      "\n",
      "-------------\n",
      "model: ibcf,\n",
      "topN: 10\n",
      "recall:5.27 %\n"
     ]
    }
   ],
   "source": [
    "uids = np.arange(0,train.shape[0])\n",
    "print('======bm25 similarity =====')\n",
    "predall_u_bm25 = model_u_bm25.predict(uids,topN=10) # np array (itemidx)\n",
    "model_u_bm25.evaluate(predall_u_bm25,test,method='recall') # 29.27\n",
    "\n",
    "predall_i_bm25 = model_i_bm25.predict(uids,topN=10) #nparray (itemidx)\n",
    "model_i_bm25.evaluate(predall_i_bm25,test,method='recall')  \n",
    "\n",
    "# predall_p = model_p.predict(uids,topN=10) #nparray (itemidx)\n",
    "# model_p.evaluate(predall_p,test,method='recall') # 20.08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推薦清單 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fundid_names_df = pd.read_csv('../funds/fundid_to_name.csv',encoding='cp950')\n",
    "fundid_to_names = {}\n",
    "\n",
    "for d in fundid_names_df.to_dict('records'):\n",
    "    fundid_to_names[d['基金代碼']] = d['基金中文名稱']\n",
    "#%% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_recommendation_knn(data,model,user_idxs, print_output=True):\n",
    "    ## user_ids : list of user ids ,eg: ['A1234567890','B12345xxxxxx',...]\n",
    "    train = data['train']\n",
    "    test = data['test']\n",
    "    idx_to_itemid = data['idx_to_itemid']\n",
    "    idx_to_userid = data['idx_to_userid']\n",
    "    \n",
    "    uidxs = np.array(user_idxs) # convert to uidxs np.array\n",
    "    rec_fundidxs = model.predict(uidxs)\n",
    "    for _, uidx in enumerate(user_idxs):\n",
    "        known_positives_itemids = [ \n",
    "            idx_to_itemid[e] for e in train[uidx].indices\n",
    "        ]\n",
    "        known_positives_item_names = [\n",
    "            fundid_to_names[fundid] for fundid in known_positives_itemids\n",
    "        ]\n",
    "        \n",
    "        if print_output == True:\n",
    "            print(\"User %s\" % idx_to_userid[uidx])\n",
    "            print(\"     ===Known positives(top3)===\")\n",
    "\n",
    "            for x in known_positives_item_names[:3]:\n",
    "                print(\"        %s\" % x)\n",
    "\n",
    "            print(\"     ===Recommended(top3)===\")\n",
    "\n",
    "            for x in rec_fundidxs[_,:3]:\n",
    "                print(\"        %s\" % fundid_to_names[idx_to_itemid[x]])\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User D2721254300\n",
      "     ===Known positives(top3)===\n",
      "        (百元基金)摩根策略總報酬基金-JPM-A股累計(美元對沖)\n",
      "        (百元基金)永豐滬深300紅利指數基金\n",
      "        鋒裕新興市場債券基金TXD配息(美元)\n",
      "     ===Recommended(top3)===\n",
      "        路博邁投資基金-NB新興市場股票基金T累積類股(美元)\n",
      "        (百元基金)貝萊德世界礦業基金(美元)\n",
      "        (百元基金)摩根俄羅斯基金-JPM-A股分派(美元)\n",
      "\n",
      "\n",
      "User N2221823430\n",
      "     ===Known positives(top3)===\n",
      "        (百元基金)摩根策略總報酬基金-JPM-A股累計(美元對沖)\n",
      "        摩根亞太入息基金-JPM-A股每月派息(美元)\n",
      "        摩根多重收益基金-JPM-A股每月派息(美元對沖)\n",
      "     ===Recommended(top3)===\n",
      "        安聯收益成長基金-AM(穩定月收類股)(美元)\n",
      "        路博邁投資基金-NB新興市場股票基金T累積類股(美元)\n",
      "        路博邁AR台灣股票基金-T月配(新臺幣)\n",
      "\n",
      "\n",
      "User D2297379550\n",
      "     ===Known positives(top3)===\n",
      "        聯博全球高收益債券基金TA月配(人民幣)\n",
      "        (百元基金)摩根策略總報酬基金-JPM-A股累計(美元對沖)\n",
      "        (百元基金)摩根俄羅斯基金-JPM-A股分派(美元)\n",
      "     ===Recommended(top3)===\n",
      "        (百元基金)富蘭克林坦伯頓全球生技領航基金(美元)\n",
      "        (百元基金)貝萊德世界黃金基金(美元)\n",
      "        安聯收益成長基金-AM(穩定月收類股)(南非幣避險)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = {'train': train, 'test':test, 'idx_to_itemid': idx_to_itemid, 'idx_to_userid':idx_to_userid}\n",
    "sample_recommendation_knn(data,model_u,[4,10,20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implicit ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize a model\n",
    "model_als = implicit.als.AlternatingLeastSquares(factors=50)\n",
    "\n",
    "train_64 = train.astype('float64')\n",
    "# train the model on a sparse matrix of item/user/confidence weights\n",
    "model_als.fit(train_64.T) \n",
    "\n",
    "# recommend items for a user\n",
    "# user_items = item_user_data.T.tocsr()\n",
    "useridx = 10\n",
    "recommendations = model_als.recommend(0, train_64)\n",
    "\n",
    "# find related items\n",
    "itemidx = 10 \n",
    "related = model_als.similar_items(itemidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of user_factor: (19748, 50)\n",
      "shape of item_factor: (2028, 50)\n"
     ]
    }
   ],
   "source": [
    "print('shape of user_factor:',model_als.user_factors.shape)\n",
    "print('shape of item_factor:',model_als.item_factors.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def calculate_mse(model, ratings, user_index=None):\n",
    "    \"\"\"Recommend products for all customers\"\"\"\n",
    "    preds = model.user_factors.dot(model.item_factors.T)\n",
    "#     preds = model.predict_for_customers()\n",
    "    if user_index:\n",
    "        return mean_squared_error(ratings[user_index, :].toarray().ravel(),\n",
    "                                  preds[user_index, :].ravel())\n",
    "    \n",
    "    return mean_squared_error(ratings.toarray().ravel(),\n",
    "                              preds.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def precision_at_k(model, ratings, k=5, user_index=None):\n",
    "    if not user_index:\n",
    "        user_index = range(ratings.shape[0])\n",
    "    ratings = ratings.tocsr()\n",
    "    precisions = []\n",
    "    # Note: line below may become infeasible for large datasets.\n",
    "#     predictions = model.predict_for_customers()\n",
    "    predictions = model.user_factors.dot(model.item_factors.T)\n",
    "    for user in user_index:\n",
    "        # In case of large dataset, compute predictions row-by-row like below\n",
    "        # predictions = np.array([model.predict(row, i) for i in xrange(ratings.shape[1])])\n",
    "        top_k = np.argsort(-predictions[user, :])[:k]\n",
    "        labels = ratings.getrow(user).indices\n",
    "        if np.any(labels):\n",
    "            precision = float(len(set(top_k) & set(labels))) / float(k)\n",
    "            precisions.append(precision)\n",
    "    return np.mean(precisions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if np.any(test.getrow(0).indices):\n",
    "    print('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_log(row, header=False, spacing=12):\n",
    "    top = ''\n",
    "    middle = ''\n",
    "    bottom = ''\n",
    "    for r in row:\n",
    "        top += '+{}'.format('-'*spacing)\n",
    "        if isinstance(r, str):\n",
    "            middle += '| {0:^{1}} '.format(r, spacing-2)\n",
    "        elif isinstance(r, int):\n",
    "            middle += '| {0:^{1}} '.format(r, spacing-2)\n",
    "        elif isinstance(r, float):\n",
    "            middle += '| {0:^{1}.5f} '.format(r, spacing-2)\n",
    "        bottom += '+{}'.format('='*spacing)\n",
    "    top += '+'\n",
    "    middle += '|'\n",
    "    bottom += '+'\n",
    "    if header:\n",
    "        print(top)\n",
    "        print(middle)\n",
    "        print(bottom)\n",
    "    else:\n",
    "        print(middle)\n",
    "        print(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+------------+\n",
      "|   hello    |     my     |    name    |     is     |\n",
      "+============+============+============+============+\n",
      "|     1      |     2      |     3      |     4      |\n",
      "+------------+------------+------------+------------+\n",
      "|  1.32000   |  1.22000   |  3.23100   |  4.21100   |\n",
      "+------------+------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "row2 = [1,2,3,4]\n",
    "row3 = [1.32,1.22,3.231,4.211]\n",
    "row = ['hello','my','name','is']\n",
    "# print_log(row)\n",
    "print_log(row, header=True, spacing=12)\n",
    "print_log(row2, header=False,spacing=12)\n",
    "print_log(row3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learning_curve(train, test, epochs, num_factor=50, regularization =0 , k=5, user_index=None):\n",
    "    if not user_index:\n",
    "        user_index = range(train.shape[0])\n",
    "    prev_epoch = 0\n",
    "    train_precision = []    \n",
    "    test_precision = []\n",
    "    topK = []\n",
    "    \n",
    "    train = train.astype('float64')\n",
    "    \n",
    "    headers = ['epochs', 'p@k train', 'p@k test','topK']\n",
    "    print_log(headers, header=True)\n",
    "    \n",
    "    for epoch in epochs:\n",
    "        model = implicit.als.AlternatingLeastSquares(factors=num_factor,iterations=epoch,regularization=regularization)\n",
    "        model.fit(train.T)\n",
    "\n",
    "        train_precision.append(precision_at_k(model, train, k, user_index))\n",
    "        test_precision.append(precision_at_k(model, test, k, user_index))\n",
    "        topK.append(k)\n",
    "        \n",
    "        row = [epoch, train_precision[-1], test_precision[-1],k]\n",
    "        \n",
    "        print_log(row)\n",
    "        prev_epoch = epoch\n",
    "    return model, train_precision, test_precision, topK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     5      |  0.26465   |  0.00975   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     10     |  0.26048   |  0.01046   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     15     |  0.25942   |  0.01024   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.25878   |  0.01024   |     10     |\n",
      "+------------+------------+------------+------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<implicit.als.AlternatingLeastSquares at 0x5476d07ba8>,\n",
       " [0.26464600425402612,\n",
       "  0.26048313582497723,\n",
       "  0.25942469360883219,\n",
       "  0.25877646105540369],\n",
       " [0.0097542437294147466,\n",
       "  0.010463643273372181,\n",
       "  0.010235621991385864,\n",
       "  0.010235621991385864],\n",
       " [10, 10, 10, 10])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_curve(train,test,epochs=[5,10,15,20],k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search_learning_curve(train, test, param_grid,\n",
    "                               user_index=None, patk=5, epochs=range(2, 40, 2)):\n",
    "    \"\"\"\n",
    "    \"Inspired\" (stolen) from sklearn gridsearch\n",
    "    https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_search.py\n",
    "    \"\"\"\n",
    "    curves = []\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    for v in itertools.product(*values):\n",
    "        params = dict(zip(keys, v))\n",
    "        \n",
    "        print_line = []\n",
    "        for k, v in params.items():            \n",
    "            print_line.append((k, v))\n",
    "\n",
    "        print(' | '.join('{}: {}'.format(k, v) for (k, v) in print_line))\n",
    "        _, train_patk, test_patk, topK = learning_curve(train, test, epochs, params.get('factors'), params.get('regularization'),\n",
    "                                                        patk, user_index=user_index)\n",
    "        curves.append({'params': params,\n",
    "                       'patk': {'train': train_patk, 'test': test_patk},\n",
    "                       })\n",
    "    return curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'factors': [5,10,20,30,40,50],\n",
    "              'regularization': [0.0, 1e-5, 1e-3, 1e-1,1e0, 1e1, 1e2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factors: 5 | regularization: 0.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.12819   |  0.02148   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.13201   |  0.02214   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.13000   |  0.02186   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.13068   |  0.02194   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 5 | regularization: 1e-05\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.13021   |  0.02181   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.13210   |  0.02247   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.13131   |  0.02255   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.13123   |  0.02184   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 5 | regularization: 0.001\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.13269   |  0.02118   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.13249   |  0.02260   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.13111   |  0.02250   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.13035   |  0.02192   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 5 | regularization: 0.1\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.12983   |  0.02105   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.13024   |  0.02192   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.13215   |  0.02192   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.13123   |  0.02242   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 5 | regularization: 1.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.13133   |  0.02217   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.13230   |  0.02222   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.13087   |  0.02199   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.13138   |  0.02192   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 5 | regularization: 10.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.13054   |  0.02194   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.13133   |  0.02214   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.13117   |  0.02230   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.12981   |  0.02212   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 5 | regularization: 100.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.07665   |  0.01604   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.07665   |  0.01604   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.07665   |  0.01604   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.07665   |  0.01604   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 10 | regularization: 0.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.15447   |  0.02002   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.15517   |  0.02085   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.15404   |  0.01943   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.15419   |  0.02065   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 10 | regularization: 1e-05\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.15492   |  0.02121   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.15420   |  0.02080   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.15454   |  0.02037   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.15498   |  0.02116   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 10 | regularization: 0.001\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.15350   |  0.02067   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.15333   |  0.02113   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.15327   |  0.01999   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.15385   |  0.01996   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 10 | regularization: 0.1\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.15306   |  0.01976   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.15335   |  0.01971   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.15329   |  0.02072   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.15675   |  0.02093   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 10 | regularization: 1.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.15473   |  0.02116   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.15526   |  0.02093   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.15329   |  0.01979   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.15304   |  0.01994   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 10 | regularization: 10.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.15240   |  0.02159   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.15361   |  0.02128   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.15245   |  0.02055   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.15274   |  0.02080   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 10 | regularization: 100.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.07666   |  0.01604   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.07665   |  0.01604   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.07665   |  0.01604   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.07666   |  0.01601   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 20 | regularization: 0.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.18895   |  0.01665   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.19161   |  0.01690   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.19168   |  0.01705   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.19114   |  0.01692   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 20 | regularization: 1e-05\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.18981   |  0.01652   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.19162   |  0.01677   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.19136   |  0.01708   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.18972   |  0.01657   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 20 | regularization: 0.001\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.18998   |  0.01637   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.18873   |  0.01621   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.19132   |  0.01670   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.18952   |  0.01728   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 20 | regularization: 0.1\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.19072   |  0.01758   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.19058   |  0.01680   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.19049   |  0.01715   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.19221   |  0.01728   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 20 | regularization: 1.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.19046   |  0.01675   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.18987   |  0.01619   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.19074   |  0.01697   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.19095   |  0.01723   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 20 | regularization: 10.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.18791   |  0.01847   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.18990   |  0.01855   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.18858   |  0.01834   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.18660   |  0.01862   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 20 | regularization: 100.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.07667   |  0.01601   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.07667   |  0.01601   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.07667   |  0.01601   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.07667   |  0.01601   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 30 | regularization: 0.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.21700   |  0.01376   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.21621   |  0.01434   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.21522   |  0.01371   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.21446   |  0.01343   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 30 | regularization: 1e-05\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.21692   |  0.01401   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.21615   |  0.01414   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.21490   |  0.01355   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.21419   |  0.01399   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 30 | regularization: 0.001\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.21650   |  0.01431   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.21515   |  0.01457   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.21453   |  0.01399   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.21495   |  0.01345   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 30 | regularization: 0.1\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.21640   |  0.01307   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.21508   |  0.01328   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.21454   |  0.01325   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.21546   |  0.01361   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 30 | regularization: 1.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.21405   |  0.01388   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.21505   |  0.01388   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.21539   |  0.01421   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.21494   |  0.01399   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 30 | regularization: 10.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.21412   |  0.01817   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.21137   |  0.01743   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.21129   |  0.01756   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.21122   |  0.01725   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 30 | regularization: 100.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.07666   |  0.01604   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.07666   |  0.01604   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.07665   |  0.01604   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.07665   |  0.01604   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 40 | regularization: 0.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.24080   |  0.01188   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.24085   |  0.01211   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.23987   |  0.01188   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.23950   |  0.01211   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 40 | regularization: 1e-05\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.24259   |  0.01163   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.23991   |  0.01198   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.23927   |  0.01198   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.23984   |  0.01193   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 40 | regularization: 0.001\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.24082   |  0.01209   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.24022   |  0.01173   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.23877   |  0.01193   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.23949   |  0.01206   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 40 | regularization: 0.1\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.24068   |  0.01120   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.24023   |  0.01181   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.23972   |  0.01188   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.23762   |  0.01236   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 40 | regularization: 1.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.23991   |  0.01173   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.23813   |  0.01198   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.23925   |  0.01214   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.23903   |  0.01221   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 40 | regularization: 10.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.23654   |  0.01713   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.23579   |  0.01776   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.23602   |  0.01763   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.23585   |  0.01784   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 40 | regularization: 100.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.07665   |  0.01604   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.07665   |  0.01604   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.07665   |  0.01604   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.07666   |  0.01604   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 50 | regularization: 0.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.26211   |  0.01036   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.26091   |  0.01079   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.26028   |  0.01018   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.25999   |  0.01029   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 50 | regularization: 1e-05\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.26181   |  0.01024   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.26042   |  0.01003   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.26003   |  0.01026   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.26026   |  0.01008   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 50 | regularization: 0.001\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.26160   |  0.00986   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.26080   |  0.01031   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.26041   |  0.01013   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.26031   |  0.01006   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 50 | regularization: 0.1\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.25874   |  0.01003   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.25958   |  0.01064   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.25935   |  0.01026   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.25978   |  0.00998   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 50 | regularization: 1.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.26015   |  0.01049   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.25981   |  0.01082   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.25955   |  0.01026   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.25941   |  0.01029   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 50 | regularization: 10.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.25643   |  0.01692   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.25640   |  0.01677   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.25561   |  0.01647   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.25606   |  0.01700   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "factors: 50 | regularization: 100.0\n",
      "+------------+------------+------------+------------+\n",
      "|   epochs   | p@k train  |  p@k test  |    topK    |\n",
      "+============+============+============+============+\n",
      "|     10     |  0.07666   |  0.01604   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     20     |  0.07666   |  0.01604   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     30     |  0.07665   |  0.01604   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "|     40     |  0.07666   |  0.01604   |     10     |\n",
      "+------------+------------+------------+------------+\n",
      "Wall time: 28min 46s\n"
     ]
    }
   ],
   "source": [
    "%time eva = grid_search_learning_curve(train,test,param_grid,patk=10,epochs = range(10,41,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning to Rank\n",
    "- lightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "import lightfm\n",
    "from lightfm.evaluation import precision_at_k,recall_at_k,reciprocal_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learning_curve_lightfm(model, train, test, eval_train,\n",
    "                        iterarray, user_features=None,\n",
    "                        item_features=None, k=5,\n",
    "                        **fit_params):\n",
    "    \"\"\"calculate learning curve for a lightfm reccommender\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    \n",
    "    model: LightFM model    \n",
    "            \n",
    "    train: csr matrix\n",
    "        training set (indcluding all users)        \n",
    "    eval_train: csr matrix\n",
    "        evaluate set (remove all non-evaluate<not in test> users' data) \n",
    "    test: csr matrix \n",
    "        test set (provide ans in a eval_train users' sets)\n",
    "    iterarray: list\n",
    "        numbers of epochs to be evaluated\n",
    "    k: int\n",
    "        numbers of recommended items\n",
    "    user_features: np.float32 csr_matrix of shape [n_users, n_user_features], optional\n",
    "        Each row contains that user’s weights over features.\n",
    "    item_features: np.float32 csr_matrix of shape [n_items, n_item_features], optional\n",
    "        Each row contains that item’s weights over features.    \n",
    "        \n",
    "    return\n",
    "    ------\n",
    "    model: LightFM \n",
    "        reccommender model     \n",
    "    train_patk: float\n",
    "        precision at k in (eval_)training data \n",
    "    test_patk: float\n",
    "        precision at k in testing data\n",
    "    train_ratk: float\n",
    "        recall at k in (eval_)training data\n",
    "    test_ratk: float\n",
    "        recall at k in testing data\n",
    "    train_rrk: float\n",
    "        reciprocal_rank at k in (eval_)training data\n",
    "    test_rrk: float\n",
    "        reciprocal_rank at k in test data\n",
    "    \"\"\"\n",
    "    old_epoch = 0\n",
    "    \n",
    "    train_patk = [] # precision at k (train)\n",
    "    test_patk = [] # precision at k (eval- train)\n",
    "    train_ratk = [] # recall at k (eval train)\n",
    "    test_ratk = [] # recall at k (test)\n",
    "    train_rrk = [] # reciprocal rank (eval train)\n",
    "    test_rrk = [] # reciprocal rank (test)\n",
    "    \n",
    "    \n",
    "    headers = ['Epoch', \n",
    "               'train p@' + str(k), \n",
    "               'test p@' + str(k)\n",
    "#                'train r@' + str(k),\n",
    "#                'test r@' + str(k),\n",
    "#                'train rr@' + str(k),\n",
    "#                'test rr@' + str(k)\n",
    "               ]\n",
    "    \n",
    "    print_log(headers, header=True)\n",
    "    \n",
    "    for epoch in iterarray:\n",
    "        more = epoch - old_epoch\n",
    "        model.fit_partial(train, \n",
    "                          user_features=user_features,\n",
    "                          item_features=item_features,\n",
    "                          epochs=more, **fit_params)\n",
    "        ## precision at k \n",
    "        this_test_pk = precision_at_k(model, test, train_interactions=train, k=k)\n",
    "        this_train_pk = precision_at_k(model, eval_train, train_interactions=train, k=k)\n",
    "        train_patk.append(np.mean(this_train_pk)) # store into list\n",
    "        test_patk.append(np.mean(this_test_pk))\n",
    "        \n",
    "        ## recall at k \n",
    "#         this_test_rk = recall_at_k(model,test,train_interactions=train,k=k)\n",
    "#         this_train_rk = recall_at_k(model,eval_train,train_interactions=train,k=k)\n",
    "#         train_ratk.append(np.mean(this_train_rk))\n",
    "#         test_ratk.append(np.mean(this_test_rk))\n",
    "                \n",
    "        ## reciprocal_rank at k\n",
    "#         this_test_rrk = reciprocal_rank(model,test)\n",
    "#         this_train_rrk = reciprocal_rank(model,eval_train)\n",
    "        \n",
    "#         train_rrk.append(np.mean(this_train_rrk))\n",
    "#         test_rrk.append(np.mean(this_test_rrk))\n",
    "        ## print log \n",
    "        row = [epoch, float(train_patk[-1]),float(test_patk[-1])] \n",
    "        print_log(row)\n",
    "        \n",
    "        old_epoch = epoch\n",
    "        \n",
    "    return model, train_patk, test_patk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+\n",
      "|   Epoch    | train p@10 | test p@10  |\n",
      "+============+============+============+\n",
      "|     1      |  0.07574   |  0.01957   |\n",
      "+------------+------------+------------+\n",
      "|     10     |  0.08129   |  0.02013   |\n",
      "+------------+------------+------------+\n",
      "|     50     |  0.10727   |  0.02342   |\n",
      "+------------+------------+------------+\n",
      "|    100     |  0.12274   |  0.02431   |\n",
      "+------------+------------+------------+\n",
      "|    150     |  0.13712   |  0.02482   |\n",
      "+------------+------------+------------+\n",
      "|    200     |  0.14710   |  0.02472   |\n",
      "+------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "eval_train = train.copy()    \n",
    "non_eval_users = list(set(range(train.shape[0])) - set(user_idxs)) ## \n",
    "eval_train = eval_train.tolil()\n",
    "for u in non_eval_users:\n",
    "    eval_train[u,:] = 0.0\n",
    "eval_train = eval_train.tocsr()\n",
    "\n",
    "model = LightFM(learning_rate=0.01, loss='warp')\n",
    "\n",
    "model_k10, train_p10, test_p10 = learning_curve_lightfm(model,train,test,eval_train,iterarray=[1,10,50,100,150,200],k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% grid search \n",
    "def grid_search_learning_curve_lightfm(base_model, train, test, eval_train,param_grid,epochs,\n",
    "                               atk=10):        \n",
    "    \"\"\"grid search \n",
    "    \n",
    "    \"Inspired\" (stolen) from sklearn gridsearch\n",
    "    https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_search.py\n",
    "    \n",
    "    \"\"\"\n",
    "    curves = []\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    for v in itertools.product(*values):\n",
    "        params = dict(zip(keys, v))\n",
    "        this_model = copy.deepcopy(base_model)\n",
    "        print_line = []\n",
    "        for k, v in params.items():\n",
    "            setattr(this_model, k, v)\n",
    "            print_line.append((k, v))\n",
    "\n",
    "        print(' | '.join('{}: {}'.format(k, v) for (k, v) in print_line))\n",
    "        _, train_patk, test_patk = learning_curve_lightfm(this_model, train, test,eval_train,epochs, k=atk)\n",
    "        \n",
    "        curves.append({'params': params,\n",
    "                       'patk': {'train': train_patk, 'test': test_patk}\n",
    "#                        'ratk': {'train': train_ratk, 'test': test_ratk},\n",
    "#                        'rratk':{'train': train_rratk, 'test':test_rratk}\n",
    "                       })\n",
    "    return curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: bpr | learning_rate: 1\n",
      "+------------+------------+------------+\n",
      "|   Epoch    | train p@10 | test p@10  |\n",
      "+============+============+============+\n",
      "|     1      |  0.15769   |  0.02408   |\n",
      "+------------+------------+------------+\n",
      "|     10     |  0.16665   |  0.01836   |\n",
      "+------------+------------+------------+\n",
      "|     50     |  0.17979   |  0.01393   |\n",
      "+------------+------------+------------+\n",
      "|    100     |  0.18060   |  0.01256   |\n",
      "+------------+------------+------------+\n",
      "|    150     |  0.17784   |  0.01185   |\n",
      "+------------+------------+------------+\n",
      "|    200     |  0.17589   |  0.01119   |\n",
      "+------------+------------+------------+\n",
      "loss: bpr | learning_rate: 0.1\n",
      "+------------+------------+------------+\n",
      "|   Epoch    | train p@10 | test p@10  |\n",
      "+============+============+============+\n",
      "|     1      |  0.14862   |  0.02494   |\n",
      "+------------+------------+------------+\n",
      "|     10     |  0.15824   |  0.02421   |\n",
      "+------------+------------+------------+\n",
      "|     50     |  0.16551   |  0.02051   |\n",
      "+------------+------------+------------+\n",
      "|    100     |  0.16728   |  0.01851   |\n",
      "+------------+------------+------------+\n",
      "|    150     |  0.17121   |  0.01707   |\n",
      "+------------+------------+------------+\n",
      "|    200     |  0.17508   |  0.01643   |\n",
      "+------------+------------+------------+\n",
      "loss: bpr | learning_rate: 0.05\n",
      "+------------+------------+------------+\n",
      "|   Epoch    | train p@10 | test p@10  |\n",
      "+============+============+============+\n",
      "|     1      |  0.14768   |  0.02484   |\n",
      "+------------+------------+------------+\n",
      "|     10     |  0.15366   |  0.02502   |\n",
      "+------------+------------+------------+\n",
      "|     50     |  0.16427   |  0.02271   |\n",
      "+------------+------------+------------+\n",
      "|    100     |  0.16533   |  0.02064   |\n",
      "+------------+------------+------------+\n",
      "|    150     |  0.16637   |  0.01932   |\n",
      "+------------+------------+------------+\n",
      "|    200     |  0.16781   |  0.01864   |\n",
      "+------------+------------+------------+\n",
      "loss: bpr | learning_rate: 0.01\n",
      "+------------+------------+------------+\n",
      "|   Epoch    | train p@10 | test p@10  |\n",
      "+============+============+============+\n",
      "|     1      |  0.14723   |  0.02482   |\n",
      "+------------+------------+------------+\n",
      "|     10     |  0.14859   |  0.02494   |\n",
      "+------------+------------+------------+\n",
      "|     50     |  0.15358   |  0.02502   |\n",
      "+------------+------------+------------+\n",
      "|    100     |  0.15867   |  0.02436   |\n",
      "+------------+------------+------------+\n",
      "|    150     |  0.16118   |  0.02411   |\n",
      "+------------+------------+------------+\n",
      "|    200     |  0.16326   |  0.02350   |\n",
      "+------------+------------+------------+\n",
      "loss: warp | learning_rate: 1\n",
      "+------------+------------+------------+\n",
      "|   Epoch    | train p@10 | test p@10  |\n",
      "+============+============+============+\n",
      "|     1      |  0.15384   |  0.02431   |\n",
      "+------------+------------+------------+\n",
      "|     10     |  0.17409   |  0.02195   |\n",
      "+------------+------------+------------+\n",
      "|     50     |  0.19843   |  0.02208   |\n",
      "+------------+------------+------------+\n",
      "|    100     |  0.20684   |  0.02208   |\n",
      "+------------+------------+------------+\n",
      "|    150     |  0.21028   |  0.02213   |\n",
      "+------------+------------+------------+\n",
      "|    200     |  0.21210   |  0.02223   |\n",
      "+------------+------------+------------+\n",
      "loss: warp | learning_rate: 0.1\n",
      "+------------+------------+------------+\n",
      "|   Epoch    | train p@10 | test p@10  |\n",
      "+============+============+============+\n",
      "|     1      |  0.14834   |  0.02484   |\n",
      "+------------+------------+------------+\n",
      "|     10     |  0.15860   |  0.02509   |\n",
      "+------------+------------+------------+\n",
      "|     50     |  0.18131   |  0.02403   |\n",
      "+------------+------------+------------+\n",
      "|    100     |  0.19068   |  0.02383   |\n",
      "+------------+------------+------------+\n",
      "|    150     |  0.19602   |  0.02350   |\n",
      "+------------+------------+------------+\n",
      "|    200     |  0.19884   |  0.02307   |\n",
      "+------------+------------+------------+\n",
      "loss: warp | learning_rate: 0.05\n",
      "+------------+------------+------------+\n",
      "|   Epoch    | train p@10 | test p@10  |\n",
      "+============+============+============+\n",
      "|     1      |  0.14773   |  0.02489   |\n",
      "+------------+------------+------------+\n",
      "|     10     |  0.15391   |  0.02522   |\n",
      "+------------+------------+------------+\n",
      "|     50     |  0.17220   |  0.02489   |\n",
      "+------------+------------+------------+\n",
      "|    100     |  0.18202   |  0.02396   |\n",
      "+------------+------------+------------+\n",
      "|    150     |  0.18754   |  0.02380   |\n",
      "+------------+------------+------------+\n",
      "|    200     |  0.19040   |  0.02358   |\n",
      "+------------+------------+------------+\n",
      "loss: warp | learning_rate: 0.01\n",
      "+------------+------------+------------+\n",
      "|   Epoch    | train p@10 | test p@10  |\n",
      "+============+============+============+\n",
      "|     1      |  0.14738   |  0.02474   |\n",
      "+------------+------------+------------+\n",
      "|     10     |  0.14834   |  0.02484   |\n",
      "+------------+------------+------------+\n",
      "|     50     |  0.15374   |  0.02494   |\n",
      "+------------+------------+------------+\n",
      "|    100     |  0.15875   |  0.02512   |\n",
      "+------------+------------+------------+\n",
      "|    150     |  0.16303   |  0.02515   |\n",
      "+------------+------------+------------+\n",
      "|    200     |  0.16589   |  0.02497   |\n",
      "+------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "grid = {\n",
    "            'loss':['bpr','warp'],\n",
    "            'learning_rate':[1,0.1,0.05,0.01]\n",
    "        }\n",
    "        \n",
    "curves = grid_search_learning_curve_lightfm(model,\n",
    "                                    train,\n",
    "                                    test,\n",
    "                                    eval_train,\n",
    "                                    grid,\n",
    "                                    epochs=[1,10,50,100,150,200],\n",
    "                                    atk=10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
